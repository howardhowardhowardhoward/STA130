{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7b49dd0",
   "metadata": {},
   "source": [
    "***Question 1***\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591c9c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived                   0\n",
      "Pclass                     0\n",
      "Name                       0\n",
      "Sex                        0\n",
      "Age                        0\n",
      "Siblings/Spouses Aboard    0\n",
      "Parents/Children Aboard    0\n",
      "Fare                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv'\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "# Check for missing values\n",
    "print(titanic_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f38b17",
   "metadata": {},
   "source": [
    "***ChatGPT Chatlog Summary***\n",
    "\n",
    "Here’s a summary of this chat session:\n",
    "\n",
    "1. **Dataset Requests**: You asked for links to datasets that can be imported into Python for analysis. I provided you with several datasets:\n",
    "   - **Iris Dataset**: A classic dataset for flower classification.\n",
    "   - **Titanic Dataset**: Data on Titanic passengers, which is useful for survival prediction.\n",
    "   - **Wine Quality Dataset**: A dataset about wine characteristics, with no missing values.\n",
    "   - **World Happiness Report**: Data on global happiness rankings.\n",
    "\n",
    "2. **Missing Values**: You requested a dataset that contains missing values. Initially, I mistakenly provided links that didn’t work, but I later corrected that with a working **Titanic Dataset** link that contains missing values in the **Age**, **Cabin**, and **Embarked** columns.\n",
    "\n",
    "3. **Python Import Instructions**: For each dataset, I provided code snippets for importing the data into Python and checking for missing values using `pandas`. For instance, checking for missing values in the Titanic dataset can be done with:\n",
    "   ```python\n",
    "   import pandas as pd\n",
    "   url = 'https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv'\n",
    "   titanic_data = pd.read_csv(url)\n",
    "   print(titanic_data.isnull().sum())\n",
    "   ```\n",
    "\n",
    "In summary, this session focused on finding datasets that you can use in Python for analysis, particularly focusing on datasets with missing values for data cleaning practice.\n",
    "\n",
    "link: https://chatgpt.com/share/0506ae9e-1d60-43e2-a50d-bc282e2eada2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ecb5ac",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2997619",
   "metadata": {},
   "source": [
    "***Question 2***\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb9b238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 887\n",
      "Number of columns: 8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')  \n",
    "# Get the number of rows and columns\n",
    "num_rows, num_columns = df.shape\n",
    "\n",
    "print(f'Number of rows: {num_rows}')\n",
    "print(f'Number of columns: {num_columns}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8afd9b9",
   "metadata": {},
   "source": [
    "**Observation** - In statistics, an observation is a single piece of qualitative or quantitative information about a given variable. A dataset is comprised of these observations. For example, in the Titanic dataset above, the female gender of a specific passenger would be a observation. These observations are often recorded in tables or graphs. \n",
    "\n",
    "**Variable** - A variable is a measurable characteristic or attribute that varies between observations. The observations of a variable can be numerical such as height, or it can be categorical such as species. Variables allow you to compare and contrast the different attributes of different entities. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fd00ef",
   "metadata": {},
   "source": [
    "***ChatGPT Chatlog Summary***\n",
    "\n",
    "Here’s a summary of our chat:\n",
    "\n",
    "1. **Dataset Information**: You asked about the Titanic dataset and the typical number of rows and columns. I explained that the dataset usually has 887 rows and 12 columns, detailing the column names.\n",
    "\n",
    "2. **Observations in Statistics**: I clarified that in statistics, \"observations\" are individual data points or records in a dataset, represented by rows in a table, and are essential for analysis.\n",
    "\n",
    "3. **Variables in Statistics**: I described that a variable is a characteristic or attribute that can vary between observations, such as age or gender. Variables can be categorical or numerical and are crucial for organizing and analyzing data.\n",
    "\n",
    "4. **Code for Data Dimensions**: I provided Python code to determine the number of rows and columns in your dataset using pandas.\n",
    "\n",
    "Feel free to use or modify this summary as needed for your homework!\n",
    "\n",
    "Link: https://chatgpt.com/share/e32c1223-d3c4-43ca-9f87-1d0d1c88e510"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d82416",
   "metadata": {},
   "source": [
    "***Question 3***\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e14265bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Survived      Pclass         Age  Siblings/Spouses Aboard  \\\n",
      "count  887.000000  887.000000  887.000000               887.000000   \n",
      "mean     0.385569    2.305524   29.471443                 0.525366   \n",
      "std      0.487004    0.836662   14.121908                 1.104669   \n",
      "min      0.000000    1.000000    0.420000                 0.000000   \n",
      "25%      0.000000    2.000000   20.250000                 0.000000   \n",
      "50%      0.000000    3.000000   28.000000                 0.000000   \n",
      "75%      1.000000    3.000000   38.000000                 1.000000   \n",
      "max      1.000000    3.000000   80.000000                 8.000000   \n",
      "\n",
      "       Parents/Children Aboard       Fare  \n",
      "count               887.000000  887.00000  \n",
      "mean                  0.383315   32.30542  \n",
      "std                   0.807466   49.78204  \n",
      "min                   0.000000    0.00000  \n",
      "25%                   0.000000    7.92500  \n",
      "50%                   0.000000   14.45420  \n",
      "75%                   0.000000   31.13750  \n",
      "max                   6.000000  512.32920  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "url = 'https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv'\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "# Get statistical summary of numerical columns\n",
    "summary = titanic_data.describe()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5337d61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Summary:\n",
      "Pclass\n",
      "3    487\n",
      "1    216\n",
      "2    184\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "categorical_summary = titanic_data['Pclass'].value_counts()\n",
    "print(\"Categorical Summary:\")\n",
    "print(categorical_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9c9fbd",
   "metadata": {},
   "source": [
    "**ChatGPT Chat Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b502657",
   "metadata": {},
   "source": [
    "Here's a summary of our chat:\n",
    "\n",
    "1. **Code Explanation:**\n",
    "   - You provided a code snippet that loads a Titanic dataset from a URL into a Pandas DataFrame and prints the count of missing values for each column.\n",
    "   - The `print(titanic_data.isnull().sum())` line shows the number of missing values per column in the dataset.\n",
    "\n",
    "2. **Using `df.describe()`:**\n",
    "   - `df.describe()` provides a statistical summary of numerical columns, including count, mean, standard deviation, min, 25th percentile, median, 75th percentile, and max.\n",
    "\n",
    "3. **Using `df['column'].value_counts()`:**\n",
    "   - `df['column'].value_counts()` provides the frequency of each unique value in a specific categorical column, helping understand the distribution of different categories.\n",
    "\n",
    "4. **Combining Both Approaches:**\n",
    "   - Use `df.describe()` for numerical columns to get a summary of their distribution.\n",
    "   - Use `df['column'].value_counts()` for categorical columns to get the frequency distribution of unique values.\n",
    "\n",
    "By using these methods, you can gain insights into both numerical and categorical data within your dataset.\n",
    "\n",
    "link: https://chatgpt.com/share/aefe9fe9-b4d1-4427-86e1-4f6a78169548"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2889a7",
   "metadata": {},
   "source": [
    "***Question 4***\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83edfa09",
   "metadata": {},
   "source": [
    "Using the df.shape function in pandas, the reported number of rows for the Titanic dataset is 887 while the reported number of collumns in the dataset is 7. However, using the df.describe() function only two collumns appear: Age and Fare. This is because the other collumns/variables contain non-numerical values which cannot be counted. The count value for Age is also less than the count value for Fare because there are missing data entries in the Age dataset.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b007455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(887, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "url = 'https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv'\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the DataFrame\n",
    "shape = titanic_data.shape\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e49254f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Survived      Pclass         Age  Siblings/Spouses Aboard  \\\n",
      "count  887.000000  887.000000  887.000000               887.000000   \n",
      "mean     0.385569    2.305524   29.471443                 0.525366   \n",
      "std      0.487004    0.836662   14.121908                 1.104669   \n",
      "min      0.000000    1.000000    0.420000                 0.000000   \n",
      "25%      0.000000    2.000000   20.250000                 0.000000   \n",
      "50%      0.000000    3.000000   28.000000                 0.000000   \n",
      "75%      1.000000    3.000000   38.000000                 1.000000   \n",
      "max      1.000000    3.000000   80.000000                 8.000000   \n",
      "\n",
      "       Parents/Children Aboard       Fare  \n",
      "count               887.000000  887.00000  \n",
      "mean                  0.383315   32.30542  \n",
      "std                   0.807466   49.78204  \n",
      "min                   0.000000    0.00000  \n",
      "25%                   0.000000    7.92500  \n",
      "50%                   0.000000   14.45420  \n",
      "75%                   0.000000   31.13750  \n",
      "max                   6.000000  512.32920  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "url = 'https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv'\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "# Get summary statistics for numerical columns\n",
    "summary = titanic_data.describe()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efd62bc",
   "metadata": {},
   "source": [
    "**ChatGPT chatlog**\n",
    "\n",
    "Here’s a summary of our chat:\n",
    "\n",
    "1. **Code Explanation:**\n",
    "   - Your code snippet loads the Titanic dataset from a URL into a Pandas DataFrame and prints the count of missing values for each column.\n",
    "\n",
    "2. **Using `df.describe()`:**\n",
    "   - `df.describe()` provides a statistical summary of numerical columns in the DataFrame, including count, mean, standard deviation, minimum, percentiles, and maximum values.\n",
    "\n",
    "3. **Using `df['column'].value_counts()`:**\n",
    "   - `df['column'].value_counts()` shows the frequency of each unique value in a specific categorical column.\n",
    "\n",
    "4. **Combining Both Approaches:**\n",
    "   - Use `df.describe()` for numerical columns to understand their distribution.\n",
    "   - Use `df['column'].value_counts()` for categorical columns to understand the distribution of categories.\n",
    "\n",
    "5. **`df.shape` Method:**\n",
    "   - `df.shape` provides the dimensions of the DataFrame, returning a tuple with the number of rows and columns.\n",
    "\n",
    "6. **`df.describe()` Details:**\n",
    "   - `df.describe()` includes count, mean, standard deviation, minimum, percentiles, and maximum values for numerical columns. You can use `df.describe(include='all')` to include categorical columns as well.\n",
    "\n",
    "link: https://chatgpt.com/share/aefe9fe9-b4d1-4427-86e1-4f6a78169548"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63772dc1",
   "metadata": {},
   "source": [
    "***Question 5***\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b653f20",
   "metadata": {},
   "source": [
    "In pandas, **attributes** usually display some feature of the dataset. For example, the df.shape function shows us how big the particular dataset is. Attributes are called without parenthesis. On the other hand, methods usually perform some action on the dataset or manipulate the dataset in some way. For example, the df.describe() function calculates the mean and variance of variables. Methods are called with parenthesis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888f4101",
   "metadata": {},
   "source": [
    "**ChatGPT Chat Log**\n",
    "Sure! Here’s a summary of our chat:\n",
    "\n",
    "- **Difference Between Attribute and Method in Pandas**:\n",
    "  - **Attribute**: Provides information about a pandas object (e.g., `df.shape` gives the dimensions of a DataFrame) and is accessed without parenthesis.\n",
    "  - **Method**: Performs actions or operations on a pandas object (e.g., `df.head()` returns the first few rows) and is called with parenthesis.\n",
    " \n",
    "Link: https://chatgpt.com/share/82d70231-3d87-4292-91ba-cf68403d2811"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a595a2a",
   "metadata": {},
   "source": [
    "***Question 6***\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2a22ca",
   "metadata": {},
   "source": [
    "In the summary statistics of the df.describe() method, the **count** of a column refers to the number of non-null entries in that particular column. The **mean** of a column refers to the mathematical average for all entries into that column. It can be calculated by summing up all entries in the column and then dividing that sum by the count of the column.  The **std** of a column refers to the standard deviation of the column, or how spread out the data is. A higher **std** implies that the data is more spread out. The **min** of a column refers to the value of the smallest data entry in that column and likewise, the **max** of a column refers to the value of the biggest data entry in that column. **25%** refers to the first quartile value. This means that exactly 25% of the entries in the data set are smaller than the first 25% value. Similairly exactly 50% of the data set is smaller than the **50%** value and exactly 75% of the data set is smaller than the **75%** value.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b536f4",
   "metadata": {},
   "source": [
    "**Question 7**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0a92be",
   "metadata": {},
   "source": [
    "1. Using df.dropna() would be preferred over using del df['col'] when we want to know all the attributes of complete data entries. For example, if there was a class survey and we wanted to know the name, age, and sex of all students who fully completed the class survey we would use df.dropna() instead of del df['col'].   \n",
    "\\\n",
    "\n",
    "2. Using del df['col'] would be preferred over using df.dropna() if we want to know only certain attributes about the data entries. For example, if we only wanted to know the names of the students who did the survey we would use del df['age'] and del df['sex'].       \n",
    "\\\n",
    "\n",
    "3. del df['col'] is more time efficient than df.dropna() because it does not require the computer to look through every single row and collumn for missing values. If we know that we already don't need a column, we can delete it first so that the computer doesn't search through that column's values when we are deleting the necessary rows. \n",
    "\n",
    "\\\n",
    "4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f488006e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#             0\n",
      "Name          0\n",
      "Type 1        0\n",
      "HP            0\n",
      "Attack        0\n",
      "Defense       0\n",
      "Sp. Atk       0\n",
      "Sp. Def       0\n",
      "Speed         0\n",
      "Generation    0\n",
      "Legendary     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "data = pd.read_csv(url)\n",
    "del data['Type 2']\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79e26e4",
   "metadata": {},
   "source": [
    "***ChatGPT Chat Logs***\n",
    "\n",
    "In our conversation, you initially asked about the function of `del df['col']` in pandas. I explained that this command deletes the specified column from a DataFrame, regardless of whether it contains missing data. An example demonstrated how this removes a column entirely from the DataFrame.\n",
    "\n",
    "Next, you inquired about `df.dropna()`, which removes rows or columns with `NaN` values. By default, it drops rows containing any missing data, but parameters like `axis` and `how` allow for more control, such as dropping columns or handling rows where all values are missing.\n",
    "\n",
    "You then asked if `del df['name']` would remove columns with incomplete data entries, and I clarified that it does not. Instead, to remove columns with missing data, you would use `df.dropna(axis=1)`. This method ensures columns with `NaN` values are specifically targeted, unlike the manual deletion with `del`.\n",
    "\n",
    "link: https://chatgpt.com/share/a874f911-b940-4a85-84ef-72f0a644e0e2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24844104",
   "metadata": {},
   "source": [
    "***Question 8***\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6ed57d",
   "metadata": {},
   "source": [
    "1. First, the groupby('col1') method groups all rows with the same 'col1' value together in the pokemon dataset. Second, the ['col2'] attribute selects the second column of all data entries in all the groups created above, and performs a describe() method where it outputs the mean, count, std, max, min, 25%, 50%, and 75% of the collumn 2s of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "047bfb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type 1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bug</th>\n",
       "      <td>69.0</td>\n",
       "      <td>70.971014</td>\n",
       "      <td>37.040904</td>\n",
       "      <td>10.0</td>\n",
       "      <td>45.00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dark</th>\n",
       "      <td>31.0</td>\n",
       "      <td>88.387097</td>\n",
       "      <td>25.774247</td>\n",
       "      <td>50.0</td>\n",
       "      <td>65.00</td>\n",
       "      <td>88.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dragon</th>\n",
       "      <td>32.0</td>\n",
       "      <td>112.125000</td>\n",
       "      <td>33.742622</td>\n",
       "      <td>50.0</td>\n",
       "      <td>86.25</td>\n",
       "      <td>113.5</td>\n",
       "      <td>134.25</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electric</th>\n",
       "      <td>44.0</td>\n",
       "      <td>69.090909</td>\n",
       "      <td>23.764169</td>\n",
       "      <td>30.0</td>\n",
       "      <td>53.75</td>\n",
       "      <td>65.0</td>\n",
       "      <td>85.00</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairy</th>\n",
       "      <td>17.0</td>\n",
       "      <td>61.529412</td>\n",
       "      <td>29.751298</td>\n",
       "      <td>20.0</td>\n",
       "      <td>45.00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>72.00</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fighting</th>\n",
       "      <td>27.0</td>\n",
       "      <td>96.777778</td>\n",
       "      <td>28.290163</td>\n",
       "      <td>35.0</td>\n",
       "      <td>80.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fire</th>\n",
       "      <td>52.0</td>\n",
       "      <td>84.769231</td>\n",
       "      <td>28.769275</td>\n",
       "      <td>30.0</td>\n",
       "      <td>62.25</td>\n",
       "      <td>84.5</td>\n",
       "      <td>101.00</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flying</th>\n",
       "      <td>4.0</td>\n",
       "      <td>78.750000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>85.0</td>\n",
       "      <td>103.75</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ghost</th>\n",
       "      <td>32.0</td>\n",
       "      <td>73.781250</td>\n",
       "      <td>29.629687</td>\n",
       "      <td>30.0</td>\n",
       "      <td>53.75</td>\n",
       "      <td>66.0</td>\n",
       "      <td>92.75</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grass</th>\n",
       "      <td>70.0</td>\n",
       "      <td>73.214286</td>\n",
       "      <td>25.380520</td>\n",
       "      <td>27.0</td>\n",
       "      <td>55.00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>93.50</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ground</th>\n",
       "      <td>32.0</td>\n",
       "      <td>95.750000</td>\n",
       "      <td>33.059087</td>\n",
       "      <td>40.0</td>\n",
       "      <td>72.00</td>\n",
       "      <td>85.0</td>\n",
       "      <td>121.00</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ice</th>\n",
       "      <td>24.0</td>\n",
       "      <td>72.750000</td>\n",
       "      <td>27.289511</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>67.0</td>\n",
       "      <td>87.50</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>98.0</td>\n",
       "      <td>73.469388</td>\n",
       "      <td>30.295862</td>\n",
       "      <td>5.0</td>\n",
       "      <td>55.00</td>\n",
       "      <td>70.5</td>\n",
       "      <td>85.00</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poison</th>\n",
       "      <td>28.0</td>\n",
       "      <td>74.678571</td>\n",
       "      <td>19.630010</td>\n",
       "      <td>43.0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>74.0</td>\n",
       "      <td>90.50</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Psychic</th>\n",
       "      <td>57.0</td>\n",
       "      <td>71.456140</td>\n",
       "      <td>42.309265</td>\n",
       "      <td>20.0</td>\n",
       "      <td>45.00</td>\n",
       "      <td>57.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rock</th>\n",
       "      <td>44.0</td>\n",
       "      <td>92.863636</td>\n",
       "      <td>35.325458</td>\n",
       "      <td>40.0</td>\n",
       "      <td>59.75</td>\n",
       "      <td>95.0</td>\n",
       "      <td>120.25</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steel</th>\n",
       "      <td>27.0</td>\n",
       "      <td>92.703704</td>\n",
       "      <td>30.388276</td>\n",
       "      <td>24.0</td>\n",
       "      <td>77.50</td>\n",
       "      <td>89.0</td>\n",
       "      <td>110.00</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water</th>\n",
       "      <td>112.0</td>\n",
       "      <td>74.151786</td>\n",
       "      <td>28.377192</td>\n",
       "      <td>10.0</td>\n",
       "      <td>53.00</td>\n",
       "      <td>72.0</td>\n",
       "      <td>92.00</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count        mean        std   min    25%    50%     75%    max\n",
       "Type 1                                                                   \n",
       "Bug        69.0   70.971014  37.040904  10.0  45.00   65.0   90.00  185.0\n",
       "Dark       31.0   88.387097  25.774247  50.0  65.00   88.0  100.00  150.0\n",
       "Dragon     32.0  112.125000  33.742622  50.0  86.25  113.5  134.25  180.0\n",
       "Electric   44.0   69.090909  23.764169  30.0  53.75   65.0   85.00  123.0\n",
       "Fairy      17.0   61.529412  29.751298  20.0  45.00   52.0   72.00  131.0\n",
       "Fighting   27.0   96.777778  28.290163  35.0  80.00  100.0  120.00  145.0\n",
       "Fire       52.0   84.769231  28.769275  30.0  62.25   84.5  101.00  160.0\n",
       "Flying      4.0   78.750000  37.500000  30.0  60.00   85.0  103.75  115.0\n",
       "Ghost      32.0   73.781250  29.629687  30.0  53.75   66.0   92.75  165.0\n",
       "Grass      70.0   73.214286  25.380520  27.0  55.00   70.0   93.50  132.0\n",
       "Ground     32.0   95.750000  33.059087  40.0  72.00   85.0  121.00  180.0\n",
       "Ice        24.0   72.750000  27.289511  30.0  50.00   67.0   87.50  130.0\n",
       "Normal     98.0   73.469388  30.295862   5.0  55.00   70.5   85.00  160.0\n",
       "Poison     28.0   74.678571  19.630010  43.0  60.00   74.0   90.50  106.0\n",
       "Psychic    57.0   71.456140  42.309265  20.0  45.00   57.0   95.00  190.0\n",
       "Rock       44.0   92.863636  35.325458  40.0  59.75   95.0  120.25  165.0\n",
       "Steel      27.0   92.703704  30.388276  24.0  77.50   89.0  110.00  150.0\n",
       "Water     112.0   74.151786  28.377192  10.0  53.00   72.0   92.00  155.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv(\"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\")\n",
    "grouped = titanic.groupby('Type 1')\n",
    "grouped['Attack'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cebe1b",
   "metadata": {},
   "source": [
    "2. df.describe() displays the overall number of non-null values in each collumn, but df.groupby('col1')['col2'].describe() tells you the count of non-null values of col2 in each group of rows with the same 'col1' value.  \n",
    "/\n",
    "3. I believe that a google search is more efficient for fixing errors which are generic such as errors A and C, but ChatGPT is a better way to fix errors that are more specific to your code such as errors E and G. This is because Google will usually give a short, straight to the point answer while ChatGPT outputs a long winded detailed answer to your question. If the error is generic Google will solve my issue quicker, but if my issue is very specific to my code then I need a more detailed fix. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1064b11e",
   "metadata": {},
   "source": [
    "***Question 9***\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba56a74",
   "metadata": {},
   "source": [
    "Yes, I have."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
