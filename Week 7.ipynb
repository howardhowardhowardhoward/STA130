{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c770c8b",
   "metadata": {},
   "source": [
    "***Question 1***\n",
    "---\n",
    "\n",
    "1. In simple linear regression, we use one predictor variable with a singular slope coefficient. In multiple linear regression, we use multiple predictor variables with multiple slope coefficients. The latter allows us to examine the relationship between the different predictor variables to produce the outcome variable. \n",
    "\n",
    "2. An indicator variable categorizes the data and can only produce 0 or 1. A continuous variable produces a spectrum of values, not dependent on the category the data is in.  \n",
    "\n",
    "3. Two parallel linear lines are produced with different starting points/intercepts. \n",
    "\n",
    "4. We can create different slopes for data in different categories. \n",
    "\n",
    "5. When the model contains only indicator variable. We get a constant line which jumps around and takes on different values. \n",
    "\n",
    "***ChatGPT Chat Summary***\n",
    "\n",
    "Here's a summary of our conversation:\n",
    "\n",
    "1. We discussed the **difference between continuous and indicator (dummy) variables** in Simple Linear Regression. Continuous variables capture a measurable, linear trend in data, while indicator variables compare groups by representing categorical information with binary values.\n",
    "\n",
    "2. We examined **adding an interaction term between a continuous and an indicator variable** in Multiple Linear Regression. This allows the model to have separate slopes for each group defined by the indicator variable, providing insights into how the continuous variable’s effect varies across groups.\n",
    "\n",
    "3. Lastly, we explored the **behavior of a Multiple Linear Regression model that includes only indicator variables derived from a non-binary categorical variable**. Such a model, with no continuous predictors, can only estimate different group means for each category, with each indicator variable representing a binary encoding for the categories. This approach enables comparisons among groups but doesn’t model trends within them.\n",
    "\n",
    "link: https://chatgpt.com/share/672e6d27-f53c-800d-93dd-b73b3e4b446b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ead46e",
   "metadata": {},
   "source": [
    "***Question 2***\n",
    "---\n",
    "\n",
    "1. The predictor variable for the situation described below is \"time spent watching television\", while the outcome variable would be something which measures the effectiveness of online advertisement such as \"number of products sold online\". Similairly, the predictor variable for the situation above would be \"Time spent online\" and the outcome would be \"number of products sold on TV\". Combining these two, we get $Sales = \\beta_0 + \\beta_1(Online) + \\beta_2(TV)$. <br>\n",
    "<br>\n",
    "2. We model the relationship with indicator variables. So in our first equation the indicator variable produces a 1 when TV watching time is high and 0 otherwise. Similairly, the indicator variable produces a 1 when online time is high and 0 otherwise. <br>\n",
    "\n",
    "***ChatGPT Chat Summary***\n",
    "\n",
    "Here's a summary of our conversation:\n",
    "\n",
    "1. We discussed the **difference between continuous and indicator variables** in Simple Linear Regression, where continuous variables represent measurable values, while indicator variables represent categorical data as binary values.\n",
    "\n",
    "2. We explored **adding interaction terms** between continuous and indicator variables in **Multiple Linear Regression**, allowing the model to account for how the effect of one variable might change depending on the value of another.\n",
    "\n",
    "3. We reviewed a scenario with a company selling sports equipment, considering how advertising on TV and online platforms can interact. We examined **two models**: one without interaction, where the effects of TV and online ad spending are treated independently, and one with interaction, which allows the effect of one type of advertising to depend on the other.\n",
    "\n",
    "4. We discussed how to update prediction models when **advertisement budgets** are categorized as **high** or **low** (binary variables) rather than continuous. We explained how the interaction model allows for a combined effect when both budgets are high, capturing any synergy between the two ad types.\n",
    "\n",
    "5. Lastly, I explained how to **add line spaces** between numbered points in Markdown by inserting blank lines or using the `<br>` tag for more control over spacing.\n",
    "link: https://chatgpt.com/share/672e6d27-f53c-800d-93dd-b73b3e4b446b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d592f40",
   "metadata": {},
   "source": [
    "***Question 4***\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d8096af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>719</td>\n",
       "      <td>Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>719</td>\n",
       "      <td>DiancieMega Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Unbound</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Dark</td>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>721</td>\n",
       "      <td>Volcanion</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Water</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                   Name   Type 1  Type 2  HP  Attack  Defense  \\\n",
       "0      1              Bulbasaur    Grass  Poison  45      49       49   \n",
       "1      2                Ivysaur    Grass  Poison  60      62       63   \n",
       "2      3               Venusaur    Grass  Poison  80      82       83   \n",
       "3      3  VenusaurMega Venusaur    Grass  Poison  80     100      123   \n",
       "4      4             Charmander     Fire     NaN  39      52       43   \n",
       "..   ...                    ...      ...     ...  ..     ...      ...   \n",
       "795  719                Diancie     Rock   Fairy  50     100      150   \n",
       "796  719    DiancieMega Diancie     Rock   Fairy  50     160      110   \n",
       "797  720    HoopaHoopa Confined  Psychic   Ghost  80     110       60   \n",
       "798  720     HoopaHoopa Unbound  Psychic    Dark  80     160       60   \n",
       "799  721              Volcanion     Fire   Water  80     110      120   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0         65       65     45           1      False  \n",
       "1         80       80     60           1      False  \n",
       "2        100      100     80           1      False  \n",
       "3        122      120     80           1      False  \n",
       "4         60       50     65           1      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "795      100      150     50           6       True  \n",
       "796      160      110    110           6       True  \n",
       "797      150      130     70           6       True  \n",
       "798      170      130     80           6       True  \n",
       "799      130       90     70           6       True  \n",
       "\n",
       "[800 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "# fail https://github.com/KeithGalli/pandas/blob/master/pokemon_data.csv\n",
    "pokeaman = pd.read_csv(url) \n",
    "pokeaman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e907331a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>3.50e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:09:01</td>     <th>  Log-Likelihood:    </th> <td> -3649.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   800</td>      <th>  AIC:               </th> <td>   7323.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   788</td>      <th>  BIC:               </th> <td>   7379.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                       <td>   26.8971</td> <td>    5.246</td> <td>    5.127</td> <td> 0.000</td> <td>   16.599</td> <td>   37.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>              <td>   20.0449</td> <td>    7.821</td> <td>    2.563</td> <td> 0.011</td> <td>    4.692</td> <td>   35.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>              <td>   21.3662</td> <td>    6.998</td> <td>    3.053</td> <td> 0.002</td> <td>    7.629</td> <td>   35.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>              <td>   31.9575</td> <td>    8.235</td> <td>    3.881</td> <td> 0.000</td> <td>   15.793</td> <td>   48.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>              <td>    9.4926</td> <td>    7.883</td> <td>    1.204</td> <td> 0.229</td> <td>   -5.982</td> <td>   24.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>              <td>   22.2693</td> <td>    8.709</td> <td>    2.557</td> <td> 0.011</td> <td>    5.173</td> <td>   39.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                    <td>    0.5634</td> <td>    0.071</td> <td>    7.906</td> <td> 0.000</td> <td>    0.423</td> <td>    0.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.2]</th> <td>   -0.2350</td> <td>    0.101</td> <td>   -2.316</td> <td> 0.021</td> <td>   -0.434</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.3]</th> <td>   -0.3067</td> <td>    0.093</td> <td>   -3.300</td> <td> 0.001</td> <td>   -0.489</td> <td>   -0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.4]</th> <td>   -0.3790</td> <td>    0.105</td> <td>   -3.600</td> <td> 0.000</td> <td>   -0.586</td> <td>   -0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.5]</th> <td>   -0.0484</td> <td>    0.108</td> <td>   -0.447</td> <td> 0.655</td> <td>   -0.261</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.6]</th> <td>   -0.3083</td> <td>    0.112</td> <td>   -2.756</td> <td> 0.006</td> <td>   -0.528</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>337.229</td> <th>  Durbin-Watson:     </th> <td>   1.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2871.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.684</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.649</td>  <th>  Cond. No.          </th> <td>1.40e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                  &        HP        & \\textbf{  R-squared:         } &     0.176   \\\\\n",
       "\\textbf{Model:}                          &       OLS        & \\textbf{  Adj. R-squared:    } &     0.164   \\\\\n",
       "\\textbf{Method:}                         &  Least Squares   & \\textbf{  F-statistic:       } &     15.27   \\\\\n",
       "\\textbf{Date:}                           & Tue, 12 Nov 2024 & \\textbf{  Prob (F-statistic):} &  3.50e-27   \\\\\n",
       "\\textbf{Time:}                           &     20:09:01     & \\textbf{  Log-Likelihood:    } &   -3649.4   \\\\\n",
       "\\textbf{No. Observations:}               &         800      & \\textbf{  AIC:               } &     7323.   \\\\\n",
       "\\textbf{Df Residuals:}                   &         788      & \\textbf{  BIC:               } &     7379.   \\\\\n",
       "\\textbf{Df Model:}                       &          11      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                         & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                       &      26.8971  &        5.246     &     5.127  &         0.000        &       16.599    &       37.195     \\\\\n",
       "\\textbf{C(Generation)[T.2]}              &      20.0449  &        7.821     &     2.563  &         0.011        &        4.692    &       35.398     \\\\\n",
       "\\textbf{C(Generation)[T.3]}              &      21.3662  &        6.998     &     3.053  &         0.002        &        7.629    &       35.103     \\\\\n",
       "\\textbf{C(Generation)[T.4]}              &      31.9575  &        8.235     &     3.881  &         0.000        &       15.793    &       48.122     \\\\\n",
       "\\textbf{C(Generation)[T.5]}              &       9.4926  &        7.883     &     1.204  &         0.229        &       -5.982    &       24.968     \\\\\n",
       "\\textbf{C(Generation)[T.6]}              &      22.2693  &        8.709     &     2.557  &         0.011        &        5.173    &       39.366     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                    &       0.5634  &        0.071     &     7.906  &         0.000        &        0.423    &        0.703     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.2]} &      -0.2350  &        0.101     &    -2.316  &         0.021        &       -0.434    &       -0.036     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.3]} &      -0.3067  &        0.093     &    -3.300  &         0.001        &       -0.489    &       -0.124     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.4]} &      -0.3790  &        0.105     &    -3.600  &         0.000        &       -0.586    &       -0.172     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.5]} &      -0.0484  &        0.108     &    -0.447  &         0.655        &       -0.261    &        0.164     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.6]} &      -0.3083  &        0.112     &    -2.756  &         0.006        &       -0.528    &       -0.089     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 337.229 & \\textbf{  Durbin-Watson:     } &    1.505  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2871.522  \\\\\n",
       "\\textbf{Skew:}          &   1.684 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  11.649 & \\textbf{  Cond. No.          } & 1.40e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.4e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.176\n",
       "Model:                            OLS   Adj. R-squared:                  0.164\n",
       "Method:                 Least Squares   F-statistic:                     15.27\n",
       "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           3.50e-27\n",
       "Time:                        20:09:01   Log-Likelihood:                -3649.4\n",
       "No. Observations:                 800   AIC:                             7323.\n",
       "Df Residuals:                     788   BIC:                             7379.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "Intercept                          26.8971      5.246      5.127      0.000      16.599      37.195\n",
       "C(Generation)[T.2]                 20.0449      7.821      2.563      0.011       4.692      35.398\n",
       "C(Generation)[T.3]                 21.3662      6.998      3.053      0.002       7.629      35.103\n",
       "C(Generation)[T.4]                 31.9575      8.235      3.881      0.000      15.793      48.122\n",
       "C(Generation)[T.5]                  9.4926      7.883      1.204      0.229      -5.982      24.968\n",
       "C(Generation)[T.6]                 22.2693      8.709      2.557      0.011       5.173      39.366\n",
       "Q(\"Sp. Def\")                        0.5634      0.071      7.906      0.000       0.423       0.703\n",
       "Q(\"Sp. Def\"):C(Generation)[T.2]    -0.2350      0.101     -2.316      0.021      -0.434      -0.036\n",
       "Q(\"Sp. Def\"):C(Generation)[T.3]    -0.3067      0.093     -3.300      0.001      -0.489      -0.124\n",
       "Q(\"Sp. Def\"):C(Generation)[T.4]    -0.3790      0.105     -3.600      0.000      -0.586      -0.172\n",
       "Q(\"Sp. Def\"):C(Generation)[T.5]    -0.0484      0.108     -0.447      0.655      -0.261       0.164\n",
       "Q(\"Sp. Def\"):C(Generation)[T.6]    -0.3083      0.112     -2.756      0.006      -0.528      -0.089\n",
       "==============================================================================\n",
       "Omnibus:                      337.229   Durbin-Watson:                   1.505\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2871.522\n",
       "Skew:                           1.684   Prob(JB):                         0.00\n",
       "Kurtosis:                      11.649   Cond. No.                     1.40e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model1_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation) + Q(\"Sp. Def\"):C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") * C(Generation)', data=pokeaman)\n",
    "\n",
    "model2_fit = model2_spec.fit()\n",
    "model2_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52e215a",
   "metadata": {},
   "source": [
    "The p value of the coefficients provides evidence againts the null hypothesis that $\\beta_1 = 0$, while a low $R^2$ value indicates that there is a high level of variance around our proposed linear regression line. These two can coexist because the predictor variable can significantly impact the outcome variable, but the degree of impact on the outcome variable may be highly variable.\n",
    "\n",
    "In essence, R² tells you how much of the variation in the outcome is explained by the model, while p-values indicate whether the individual predictors significantly contribute to explaining the outcome. The low R² suggests that the model does not explain much of the total variability, while the significant coefficients suggest that the predictors in the model do have a meaningful relationship with the outcome. The predictors may be significant but do not account for a large portion of the variability.\n",
    "\n",
    "***ChatGPT Chat log***\n",
    "Here's a summary of our discussion:\n",
    "\n",
    "- **R² (Explained Variability)**: Tells us how much of the total variability in the dependent variable is explained by the predictors. A low R² (17.6%) means that the model does not explain much of the variation in the data, implying there may be missing important variables or that the model is oversimplified.\n",
    "\n",
    "- **P-values and Coefficients**: P-values assess whether individual predictors have a significant effect on the outcome. Low p-values for predictors indicate that these variables **are statistically significant**, meaning they are related to the outcome even if they do not explain much of the total variability (as indicated by the low R²).\n",
    "\n",
    "- **Why This Happens**: R² and p-values measure different aspects:\n",
    "  - R² measures **overall explanatory power**, and a low R² suggests the model misses key factors.\n",
    "  - P-values assess the **individual significance** of predictors, and significant predictors (with low p-values) show that certain variables do influence the outcome, even if the model as a whole does not explain much of the variability.\n",
    "\n",
    "- **Key Point**: The apparent contradiction occurs because the two metrics address **different questions**. A low R² doesn't mean predictors aren't important, but rather that the model doesn't capture all the variability in the outcome. Significant p-values indicate the predictors are still meaningfully related to the outcome. Both metrics are **complementary** rather than contradictory.\n",
    "\n",
    "link: https://chatgpt.com/share/672e7ad8-feb8-800d-b353-1a5c0e03a82a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5031ce62",
   "metadata": {},
   "source": [
    "***Question 5***\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3814f7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>338</td>\n",
       "      <td>Solrock</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>70</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Charizard</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Flying</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>109</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>224</td>\n",
       "      <td>Octillery</td>\n",
       "      <td>Water</td>\n",
       "      <td>None</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>600</td>\n",
       "      <td>Klang</td>\n",
       "      <td>Steel</td>\n",
       "      <td>None</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>265</td>\n",
       "      <td>Wurmple</td>\n",
       "      <td>Bug</td>\n",
       "      <td>None</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>471</td>\n",
       "      <td>Glaceon</td>\n",
       "      <td>Ice</td>\n",
       "      <td>None</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>225</td>\n",
       "      <td>Delibird</td>\n",
       "      <td>Ice</td>\n",
       "      <td>Flying</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>109</td>\n",
       "      <td>Koffing</td>\n",
       "      <td>Poison</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>373</td>\n",
       "      <td>SalamenceMega Salamence</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>Flying</td>\n",
       "      <td>95</td>\n",
       "      <td>145</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                     Name   Type 1   Type 2  HP  Attack  Defense  \\\n",
       "370  338                  Solrock     Rock  Psychic  70      95       85   \n",
       "6      6                Charizard     Fire   Flying  78      84       78   \n",
       "242  224                Octillery    Water     None  75     105       75   \n",
       "661  600                    Klang    Steel     None  60      80       95   \n",
       "288  265                  Wurmple      Bug     None  45      45       35   \n",
       "..   ...                      ...      ...      ...  ..     ...      ...   \n",
       "522  471                  Glaceon      Ice     None  65      60      110   \n",
       "243  225                 Delibird      Ice   Flying  45      55       45   \n",
       "797  720      HoopaHoopa Confined  Psychic    Ghost  80     110       60   \n",
       "117  109                  Koffing   Poison     None  40      65       95   \n",
       "409  373  SalamenceMega Salamence   Dragon   Flying  95     145      130   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "370       55       65     70           3      False  \n",
       "6        109       85    100           1      False  \n",
       "242      105       75     45           2      False  \n",
       "661       70       85     50           5      False  \n",
       "288       20       30     20           3      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "522      130       95     65           4      False  \n",
       "243       65       45     75           2      False  \n",
       "797      150      130     70           6       True  \n",
       "117       60       45     35           1      False  \n",
       "409      120       90    120           3      False  \n",
       "\n",
       "[400 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fifty_fifty_split_size = int(pokeaman.shape[0]*0.5)\n",
    "\n",
    "# Replace \"NaN\" (in the \"Type 2\" column with \"None\")\n",
    "pokeaman.fillna('None', inplace=True)\n",
    "\n",
    "np.random.seed(130)\n",
    "pokeaman_train,pokeaman_test = \\\n",
    "  train_test_split(pokeaman, train_size=fifty_fifty_split_size)\n",
    "pokeaman_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c72f53",
   "metadata": {},
   "source": [
    "The above code randomly divides the rows of the pokeman dataframe into two seperate datasets of approximately equal size: pokeman_train and pokeman_test. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd347478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:09:02</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Tue, 12 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     20:09:02     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        20:09:02   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spec3 = smf.ols(formula='HP ~ Attack + Defense', \n",
    "                      data=pokeaman_train)\n",
    "model3_fit = model_spec3.fit()\n",
    "model3_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ddef66",
   "metadata": {},
   "source": [
    "The code specifies a linear regression model with the formula:\n",
    "\n",
    "\n",
    "$$\\text{HP} = \\beta_0 + \\beta_1 \\cdot \\text{Attack} + \\beta_2 \\cdot \\text{Defense} + \\epsilon$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6181d312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.14771558304519894\n",
      "'Out of sample' R-squared: 0.21208501873920738\n"
     ]
    }
   ],
   "source": [
    "yhat_model3 = model3_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model3_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model3)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfc80f9",
   "metadata": {},
   "source": [
    "The code above gives us the R squared value for the pokeman_train linear regression line and the R squared value for pokeman_test linear regression line as 'In sample' and 'Out of sample' respectively. This reflects the models accuracy on the datasets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "263b2d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.23e-21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:09:02</td>     <th>  Log-Likelihood:    </th> <td> -1738.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3603.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   337</td>      <th>  BIC:               </th> <td>   3855.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    62</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                  <td></td>                                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                        <td>  521.5715</td> <td>  130.273</td> <td>    4.004</td> <td> 0.000</td> <td>  265.322</td> <td>  777.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>                                                <td>   -6.1179</td> <td>    2.846</td> <td>   -2.150</td> <td> 0.032</td> <td>  -11.716</td> <td>   -0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                                           <td>   -8.1938</td> <td>    2.329</td> <td>   -3.518</td> <td> 0.000</td> <td>  -12.775</td> <td>   -3.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]</th>                                         <td>-1224.9610</td> <td>  545.105</td> <td>   -2.247</td> <td> 0.025</td> <td>-2297.199</td> <td> -152.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                                                          <td>   -6.1989</td> <td>    2.174</td> <td>   -2.851</td> <td> 0.005</td> <td>  -10.475</td> <td>   -1.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]</th>                                        <td> -102.4030</td> <td>   96.565</td> <td>   -1.060</td> <td> 0.290</td> <td> -292.350</td> <td>   87.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense</th>                                                   <td>    0.0985</td> <td>    0.033</td> <td>    2.982</td> <td> 0.003</td> <td>    0.034</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]</th>                                 <td>   14.6361</td> <td>    6.267</td> <td>    2.336</td> <td> 0.020</td> <td>    2.310</td> <td>   26.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                                            <td>   -7.2261</td> <td>    2.178</td> <td>   -3.318</td> <td> 0.001</td> <td>  -11.511</td> <td>   -2.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]</th>                                          <td>  704.8798</td> <td>  337.855</td> <td>    2.086</td> <td> 0.038</td> <td>   40.309</td> <td> 1369.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                                                     <td>    0.1264</td> <td>    0.038</td> <td>    3.351</td> <td> 0.001</td> <td>    0.052</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]</th>                                   <td>    5.8648</td> <td>    2.692</td> <td>    2.179</td> <td> 0.030</td> <td>    0.570</td> <td>   11.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed</th>                                                    <td>    0.1026</td> <td>    0.039</td> <td>    2.634</td> <td> 0.009</td> <td>    0.026</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]</th>                                  <td>   -6.9266</td> <td>    3.465</td> <td>   -1.999</td> <td> 0.046</td> <td>  -13.742</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed</th>                                             <td>   -0.0016</td> <td>    0.001</td> <td>   -2.837</td> <td> 0.005</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]</th>                           <td>   -0.0743</td> <td>    0.030</td> <td>   -2.477</td> <td> 0.014</td> <td>   -0.133</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                                                     <td>   -5.3982</td> <td>    1.938</td> <td>   -2.785</td> <td> 0.006</td> <td>   -9.211</td> <td>   -1.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\")</th>                                   <td> -282.2496</td> <td>  126.835</td> <td>   -2.225</td> <td> 0.027</td> <td> -531.738</td> <td>  -32.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                                              <td>    0.1094</td> <td>    0.034</td> <td>    3.233</td> <td> 0.001</td> <td>    0.043</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\")</th>                            <td>   12.6503</td> <td>    5.851</td> <td>    2.162</td> <td> 0.031</td> <td>    1.141</td> <td>   24.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\")</th>                                             <td>    0.0628</td> <td>    0.028</td> <td>    2.247</td> <td> 0.025</td> <td>    0.008</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                           <td>    3.3949</td> <td>    1.783</td> <td>    1.904</td> <td> 0.058</td> <td>   -0.112</td> <td>    6.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\")</th>                                      <td>   -0.0012</td> <td>    0.000</td> <td>   -2.730</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                    <td>   -0.1456</td> <td>    0.065</td> <td>   -2.253</td> <td> 0.025</td> <td>   -0.273</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                                               <td>    0.0624</td> <td>    0.031</td> <td>    2.027</td> <td> 0.043</td> <td>    0.002</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                             <td>   -3.2219</td> <td>    1.983</td> <td>   -1.625</td> <td> 0.105</td> <td>   -7.122</td> <td>    0.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>                                        <td>   -0.0014</td> <td>    0.001</td> <td>   -2.732</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                      <td>   -0.0695</td> <td>    0.033</td> <td>   -2.100</td> <td> 0.036</td> <td>   -0.135</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\")</th>                                       <td>   -0.0008</td> <td>    0.000</td> <td>   -1.743</td> <td> 0.082</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                     <td>    0.0334</td> <td>    0.021</td> <td>    1.569</td> <td> 0.117</td> <td>   -0.008</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\")</th>                                <td> 1.629e-05</td> <td> 6.92e-06</td> <td>    2.355</td> <td> 0.019</td> <td> 2.68e-06</td> <td> 2.99e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>              <td>    0.0008</td> <td>    0.000</td> <td>    2.433</td> <td> 0.015</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                                                     <td>   -8.3636</td> <td>    2.346</td> <td>   -3.565</td> <td> 0.000</td> <td>  -12.978</td> <td>   -3.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Atk\")</th>                                   <td>  850.5436</td> <td>  385.064</td> <td>    2.209</td> <td> 0.028</td> <td>   93.112</td> <td> 1607.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                                              <td>    0.1388</td> <td>    0.040</td> <td>    3.500</td> <td> 0.001</td> <td>    0.061</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Atk\")</th>                            <td>    2.1809</td> <td>    1.136</td> <td>    1.920</td> <td> 0.056</td> <td>   -0.054</td> <td>    4.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Atk\")</th>                                             <td>    0.0831</td> <td>    0.038</td> <td>    2.162</td> <td> 0.031</td> <td>    0.007</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                           <td>   -7.3121</td> <td>    3.376</td> <td>   -2.166</td> <td> 0.031</td> <td>  -13.953</td> <td>   -0.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Atk\")</th>                                      <td>   -0.0014</td> <td>    0.001</td> <td>   -2.480</td> <td> 0.014</td> <td>   -0.003</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                    <td>   -0.0434</td> <td>    0.022</td> <td>   -2.010</td> <td> 0.045</td> <td>   -0.086</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                                               <td>    0.1011</td> <td>    0.035</td> <td>    2.872</td> <td> 0.004</td> <td>    0.032</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                             <td>  -12.6343</td> <td>    5.613</td> <td>   -2.251</td> <td> 0.025</td> <td>  -23.674</td> <td>   -1.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>                                        <td>   -0.0018</td> <td>    0.001</td> <td>   -3.102</td> <td> 0.002</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                      <td>    0.0151</td> <td>    0.009</td> <td>    1.609</td> <td> 0.109</td> <td>   -0.003</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Atk\")</th>                                       <td>   -0.0012</td> <td>    0.001</td> <td>   -1.860</td> <td> 0.064</td> <td>   -0.002</td> <td> 6.62e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                     <td>    0.1210</td> <td>    0.054</td> <td>    2.260</td> <td> 0.024</td> <td>    0.016</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Atk\")</th>                                <td> 2.125e-05</td> <td>  9.1e-06</td> <td>    2.334</td> <td> 0.020</td> <td> 3.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>              <td> 6.438e-06</td> <td> 7.69e-05</td> <td>    0.084</td> <td> 0.933</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                        <td>    0.1265</td> <td>    0.033</td> <td>    3.821</td> <td> 0.000</td> <td>    0.061</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                      <td>   -5.0544</td> <td>    2.506</td> <td>   -2.017</td> <td> 0.044</td> <td>   -9.983</td> <td>   -0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                 <td>   -0.0021</td> <td>    0.001</td> <td>   -3.606</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>               <td>   -0.0346</td> <td>    0.017</td> <td>   -1.992</td> <td> 0.047</td> <td>   -0.069</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                <td>   -0.0012</td> <td>    0.000</td> <td>   -2.406</td> <td> 0.017</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0446</td> <td>    0.025</td> <td>    1.794</td> <td> 0.074</td> <td>   -0.004</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                         <td> 1.973e-05</td> <td> 7.28e-06</td> <td>    2.710</td> <td> 0.007</td> <td> 5.41e-06</td> <td>  3.4e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>    0.0005</td> <td>    0.000</td> <td>    1.957</td> <td> 0.051</td> <td>-2.56e-06</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                  <td>   -0.0013</td> <td>    0.000</td> <td>   -2.740</td> <td> 0.006</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                <td>    0.0841</td> <td>    0.040</td> <td>    2.125</td> <td> 0.034</td> <td>    0.006</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                           <td> 2.379e-05</td> <td> 7.85e-06</td> <td>    3.030</td> <td> 0.003</td> <td> 8.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>         <td> 2.864e-05</td> <td> 7.73e-05</td> <td>    0.370</td> <td> 0.711</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                          <td> 1.284e-05</td> <td> 7.46e-06</td> <td>    1.721</td> <td> 0.086</td> <td>-1.83e-06</td> <td> 2.75e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0008</td> <td>    0.000</td> <td>   -2.085</td> <td> 0.038</td> <td>   -0.002</td> <td>-4.68e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                   <td> -2.53e-07</td> <td>  1.1e-07</td> <td>   -2.292</td> <td> 0.023</td> <td> -4.7e-07</td> <td>-3.59e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>-1.425e-06</td> <td> 1.14e-06</td> <td>   -1.249</td> <td> 0.212</td> <td>-3.67e-06</td> <td> 8.19e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.2e+16. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                                   &        HP        & \\textbf{  R-squared:         } &     0.467   \\\\\n",
       "\\textbf{Model:}                                                           &       OLS        & \\textbf{  Adj. R-squared:    } &     0.369   \\\\\n",
       "\\textbf{Method:}                                                          &  Least Squares   & \\textbf{  F-statistic:       } &     4.764   \\\\\n",
       "\\textbf{Date:}                                                            & Tue, 12 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.23e-21   \\\\\n",
       "\\textbf{Time:}                                                            &     20:09:02     & \\textbf{  Log-Likelihood:    } &   -1738.6   \\\\\n",
       "\\textbf{No. Observations:}                                                &         400      & \\textbf{  AIC:               } &     3603.   \\\\\n",
       "\\textbf{Df Residuals:}                                                    &         337      & \\textbf{  BIC:               } &     3855.   \\\\\n",
       "\\textbf{Df Model:}                                                        &          62      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                                                 &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                                        &     521.5715  &      130.273     &     4.004  &         0.000        &      265.322    &      777.821     \\\\\n",
       "\\textbf{Legendary[T.True]}                                                &      -6.1179  &        2.846     &    -2.150  &         0.032        &      -11.716    &       -0.520     \\\\\n",
       "\\textbf{Attack}                                                           &      -8.1938  &        2.329     &    -3.518  &         0.000        &      -12.775    &       -3.612     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]}                                         &   -1224.9610  &      545.105     &    -2.247  &         0.025        &    -2297.199    &     -152.723     \\\\\n",
       "\\textbf{Defense}                                                          &      -6.1989  &        2.174     &    -2.851  &         0.005        &      -10.475    &       -1.923     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]}                                        &    -102.4030  &       96.565     &    -1.060  &         0.290        &     -292.350    &       87.544     \\\\\n",
       "\\textbf{Attack:Defense}                                                   &       0.0985  &        0.033     &     2.982  &         0.003        &        0.034    &        0.164     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]}                                 &      14.6361  &        6.267     &     2.336  &         0.020        &        2.310    &       26.963     \\\\\n",
       "\\textbf{Speed}                                                            &      -7.2261  &        2.178     &    -3.318  &         0.001        &      -11.511    &       -2.942     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]}                                          &     704.8798  &      337.855     &     2.086  &         0.038        &       40.309    &     1369.450     \\\\\n",
       "\\textbf{Attack:Speed}                                                     &       0.1264  &        0.038     &     3.351  &         0.001        &        0.052    &        0.201     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]}                                   &       5.8648  &        2.692     &     2.179  &         0.030        &        0.570    &       11.160     \\\\\n",
       "\\textbf{Defense:Speed}                                                    &       0.1026  &        0.039     &     2.634  &         0.009        &        0.026    &        0.179     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]}                                  &      -6.9266  &        3.465     &    -1.999  &         0.046        &      -13.742    &       -0.111     \\\\\n",
       "\\textbf{Attack:Defense:Speed}                                             &      -0.0016  &        0.001     &    -2.837  &         0.005        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]}                           &      -0.0743  &        0.030     &    -2.477  &         0.014        &       -0.133    &       -0.015     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                                                     &      -5.3982  &        1.938     &    -2.785  &         0.006        &       -9.211    &       -1.586     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\")}                                   &    -282.2496  &      126.835     &    -2.225  &         0.027        &     -531.738    &      -32.761     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                                              &       0.1094  &        0.034     &     3.233  &         0.001        &        0.043    &        0.176     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\")}                            &      12.6503  &        5.851     &     2.162  &         0.031        &        1.141    &       24.160     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\")}                                             &       0.0628  &        0.028     &     2.247  &         0.025        &        0.008    &        0.118     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\")}                           &       3.3949  &        1.783     &     1.904  &         0.058        &       -0.112    &        6.902     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\")}                                      &      -0.0012  &        0.000     &    -2.730  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")}                    &      -0.1456  &        0.065     &    -2.253  &         0.025        &       -0.273    &       -0.018     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                                               &       0.0624  &        0.031     &     2.027  &         0.043        &        0.002    &        0.123     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\")}                             &      -3.2219  &        1.983     &    -1.625  &         0.105        &       -7.122    &        0.678     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}                                        &      -0.0014  &        0.001     &    -2.732  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                      &      -0.0695  &        0.033     &    -2.100  &         0.036        &       -0.135    &       -0.004     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\")}                                       &      -0.0008  &        0.000     &    -1.743  &         0.082        &       -0.002    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                     &       0.0334  &        0.021     &     1.569  &         0.117        &       -0.008    &        0.075     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\")}                                &    1.629e-05  &     6.92e-06     &     2.355  &         0.019        &     2.68e-06    &     2.99e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}              &       0.0008  &        0.000     &     2.433  &         0.015        &        0.000    &        0.001     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                                                     &      -8.3636  &        2.346     &    -3.565  &         0.000        &      -12.978    &       -3.749     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Atk\")}                                   &     850.5436  &      385.064     &     2.209  &         0.028        &       93.112    &     1607.975     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                                              &       0.1388  &        0.040     &     3.500  &         0.001        &        0.061    &        0.217     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Atk\")}                            &       2.1809  &        1.136     &     1.920  &         0.056        &       -0.054    &        4.416     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Atk\")}                                             &       0.0831  &        0.038     &     2.162  &         0.031        &        0.007    &        0.159     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                           &      -7.3121  &        3.376     &    -2.166  &         0.031        &      -13.953    &       -0.671     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Atk\")}                                      &      -0.0014  &        0.001     &    -2.480  &         0.014        &       -0.003    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                    &      -0.0434  &        0.022     &    -2.010  &         0.045        &       -0.086    &       -0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                                               &       0.1011  &        0.035     &     2.872  &         0.004        &        0.032    &        0.170     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                             &     -12.6343  &        5.613     &    -2.251  &         0.025        &      -23.674    &       -1.594     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}                                        &      -0.0018  &        0.001     &    -3.102  &         0.002        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                      &       0.0151  &        0.009     &     1.609  &         0.109        &       -0.003    &        0.034     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Atk\")}                                       &      -0.0012  &        0.001     &    -1.860  &         0.064        &       -0.002    &     6.62e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                     &       0.1210  &        0.054     &     2.260  &         0.024        &        0.016    &        0.226     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Atk\")}                                &    2.125e-05  &      9.1e-06     &     2.334  &         0.020        &     3.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}              &    6.438e-06  &     7.69e-05     &     0.084  &         0.933        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                        &       0.1265  &        0.033     &     3.821  &         0.000        &        0.061    &        0.192     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                      &      -5.0544  &        2.506     &    -2.017  &         0.044        &       -9.983    &       -0.126     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                 &      -0.0021  &        0.001     &    -3.606  &         0.000        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}               &      -0.0346  &        0.017     &    -1.992  &         0.047        &       -0.069    &       -0.000     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                &      -0.0012  &        0.000     &    -2.406  &         0.017        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0446  &        0.025     &     1.794  &         0.074        &       -0.004    &        0.093     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                         &    1.973e-05  &     7.28e-06     &     2.710  &         0.007        &     5.41e-06    &      3.4e-05     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &       0.0005  &        0.000     &     1.957  &         0.051        &    -2.56e-06    &        0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                  &      -0.0013  &        0.000     &    -2.740  &         0.006        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                &       0.0841  &        0.040     &     2.125  &         0.034        &        0.006    &        0.162     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                           &    2.379e-05  &     7.85e-06     &     3.030  &         0.003        &     8.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}         &    2.864e-05  &     7.73e-05     &     0.370  &         0.711        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                          &    1.284e-05  &     7.46e-06     &     1.721  &         0.086        &    -1.83e-06    &     2.75e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0008  &        0.000     &    -2.085  &         0.038        &       -0.002    &    -4.68e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                   &    -2.53e-07  &      1.1e-07     &    -2.292  &         0.023        &     -4.7e-07    &    -3.59e-08     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &   -1.425e-06  &     1.14e-06     &    -1.249  &         0.212        &    -3.67e-06    &     8.19e-07     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.664  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.2e+16. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.467\n",
       "Model:                            OLS   Adj. R-squared:                  0.369\n",
       "Method:                 Least Squares   F-statistic:                     4.764\n",
       "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           4.23e-21\n",
       "Time:                        20:09:02   Log-Likelihood:                -1738.6\n",
       "No. Observations:                 400   AIC:                             3603.\n",
       "Df Residuals:                     337   BIC:                             3855.\n",
       "Df Model:                          62                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================================================\n",
       "                                                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                          521.5715    130.273      4.004      0.000     265.322     777.821\n",
       "Legendary[T.True]                                                   -6.1179      2.846     -2.150      0.032     -11.716      -0.520\n",
       "Attack                                                              -8.1938      2.329     -3.518      0.000     -12.775      -3.612\n",
       "Attack:Legendary[T.True]                                         -1224.9610    545.105     -2.247      0.025   -2297.199    -152.723\n",
       "Defense                                                             -6.1989      2.174     -2.851      0.005     -10.475      -1.923\n",
       "Defense:Legendary[T.True]                                         -102.4030     96.565     -1.060      0.290    -292.350      87.544\n",
       "Attack:Defense                                                       0.0985      0.033      2.982      0.003       0.034       0.164\n",
       "Attack:Defense:Legendary[T.True]                                    14.6361      6.267      2.336      0.020       2.310      26.963\n",
       "Speed                                                               -7.2261      2.178     -3.318      0.001     -11.511      -2.942\n",
       "Speed:Legendary[T.True]                                            704.8798    337.855      2.086      0.038      40.309    1369.450\n",
       "Attack:Speed                                                         0.1264      0.038      3.351      0.001       0.052       0.201\n",
       "Attack:Speed:Legendary[T.True]                                       5.8648      2.692      2.179      0.030       0.570      11.160\n",
       "Defense:Speed                                                        0.1026      0.039      2.634      0.009       0.026       0.179\n",
       "Defense:Speed:Legendary[T.True]                                     -6.9266      3.465     -1.999      0.046     -13.742      -0.111\n",
       "Attack:Defense:Speed                                                -0.0016      0.001     -2.837      0.005      -0.003      -0.001\n",
       "Attack:Defense:Speed:Legendary[T.True]                              -0.0743      0.030     -2.477      0.014      -0.133      -0.015\n",
       "Q(\"Sp. Def\")                                                        -5.3982      1.938     -2.785      0.006      -9.211      -1.586\n",
       "Legendary[T.True]:Q(\"Sp. Def\")                                    -282.2496    126.835     -2.225      0.027    -531.738     -32.761\n",
       "Attack:Q(\"Sp. Def\")                                                  0.1094      0.034      3.233      0.001       0.043       0.176\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\")                               12.6503      5.851      2.162      0.031       1.141      24.160\n",
       "Defense:Q(\"Sp. Def\")                                                 0.0628      0.028      2.247      0.025       0.008       0.118\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\")                               3.3949      1.783      1.904      0.058      -0.112       6.902\n",
       "Attack:Defense:Q(\"Sp. Def\")                                         -0.0012      0.000     -2.730      0.007      -0.002      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")                       -0.1456      0.065     -2.253      0.025      -0.273      -0.018\n",
       "Speed:Q(\"Sp. Def\")                                                   0.0624      0.031      2.027      0.043       0.002       0.123\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\")                                -3.2219      1.983     -1.625      0.105      -7.122       0.678\n",
       "Attack:Speed:Q(\"Sp. Def\")                                           -0.0014      0.001     -2.732      0.007      -0.002      -0.000\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         -0.0695      0.033     -2.100      0.036      -0.135      -0.004\n",
       "Defense:Speed:Q(\"Sp. Def\")                                          -0.0008      0.000     -1.743      0.082      -0.002       0.000\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         0.0334      0.021      1.569      0.117      -0.008       0.075\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\")                                 1.629e-05   6.92e-06      2.355      0.019    2.68e-06    2.99e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                  0.0008      0.000      2.433      0.015       0.000       0.001\n",
       "Q(\"Sp. Atk\")                                                        -8.3636      2.346     -3.565      0.000     -12.978      -3.749\n",
       "Legendary[T.True]:Q(\"Sp. Atk\")                                     850.5436    385.064      2.209      0.028      93.112    1607.975\n",
       "Attack:Q(\"Sp. Atk\")                                                  0.1388      0.040      3.500      0.001       0.061       0.217\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Atk\")                                2.1809      1.136      1.920      0.056      -0.054       4.416\n",
       "Defense:Q(\"Sp. Atk\")                                                 0.0831      0.038      2.162      0.031       0.007       0.159\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Atk\")                              -7.3121      3.376     -2.166      0.031     -13.953      -0.671\n",
       "Attack:Defense:Q(\"Sp. Atk\")                                         -0.0014      0.001     -2.480      0.014      -0.003      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")                       -0.0434      0.022     -2.010      0.045      -0.086      -0.001\n",
       "Speed:Q(\"Sp. Atk\")                                                   0.1011      0.035      2.872      0.004       0.032       0.170\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Atk\")                               -12.6343      5.613     -2.251      0.025     -23.674      -1.594\n",
       "Attack:Speed:Q(\"Sp. Atk\")                                           -0.0018      0.001     -3.102      0.002      -0.003      -0.001\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                          0.0151      0.009      1.609      0.109      -0.003       0.034\n",
       "Defense:Speed:Q(\"Sp. Atk\")                                          -0.0012      0.001     -1.860      0.064      -0.002    6.62e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                         0.1210      0.054      2.260      0.024       0.016       0.226\n",
       "Attack:Defense:Speed:Q(\"Sp. Atk\")                                 2.125e-05    9.1e-06      2.334      0.020    3.34e-06    3.92e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")               6.438e-06   7.69e-05      0.084      0.933      -0.000       0.000\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                            0.1265      0.033      3.821      0.000       0.061       0.192\n",
       "Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                         -5.0544      2.506     -2.017      0.044      -9.983      -0.126\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                    -0.0021      0.001     -3.606      0.000      -0.003      -0.001\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  -0.0346      0.017     -1.992      0.047      -0.069      -0.000\n",
       "Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                   -0.0012      0.000     -2.406      0.017      -0.002      -0.000\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0446      0.025      1.794      0.074      -0.004       0.093\n",
       "Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                          1.973e-05   7.28e-06      2.710      0.007    5.41e-06     3.4e-05\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           0.0005      0.000      1.957      0.051   -2.56e-06       0.001\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                     -0.0013      0.000     -2.740      0.006      -0.002      -0.000\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    0.0841      0.040      2.125      0.034       0.006       0.162\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                            2.379e-05   7.85e-06      3.030      0.003    8.34e-06    3.92e-05\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          2.864e-05   7.73e-05      0.370      0.711      -0.000       0.000\n",
       "Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                           1.284e-05   7.46e-06      1.721      0.086   -1.83e-06    2.75e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0008      0.000     -2.085      0.038      -0.002   -4.68e-05\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    -2.53e-07    1.1e-07     -2.292      0.023    -4.7e-07   -3.59e-08\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\") -1.425e-06   1.14e-06     -1.249      0.212   -3.67e-06    8.19e-07\n",
       "==============================================================================\n",
       "Omnibus:                      214.307   Durbin-Watson:                   1.992\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2354.664\n",
       "Skew:                           2.026   Prob(JB):                         0.00\n",
       "Kurtosis:                      14.174   Cond. No.                     1.20e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.2e+16. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form = 'HP ~ Attack * Defense * Speed * Legendary'\n",
    "model4_linear_form += ' * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "# DO NOT try adding '* C(Generation) * C(Q(\"Type 1\")) * C(Q(\"Type 2\"))'\n",
    "# That's 6*18*19 = 6*18*19 possible interaction combinations...\n",
    "# ...a huge number that will blow up your computer\n",
    "\n",
    "model4_spec = smf.ols(formula=model4_linear_form, data=pokeaman_train)\n",
    "model4_fit = model4_spec.fit()\n",
    "model4_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45075f7b",
   "metadata": {},
   "source": [
    "Examines the linear regression relationship between Pokemon HP and its Attack, Defense, Speed, Legendary rating.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c64ed8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.46709442115833855\n",
      "'Out of sample' R-squared: 0.002485342598992873\n"
     ]
    }
   ],
   "source": [
    "yhat_model4 = model4_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model4_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model4)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5382fbb0",
   "metadata": {},
   "source": [
    "Compares the in sample and out of sample $R^2$ values. This shows us that we are overfitting the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6628ad0",
   "metadata": {},
   "source": [
    "***ChatGPT Chat Summary***\n",
    "\n",
    "We reviewed Python code for training and evaluating a complex linear regression model on Pokémon data, focusing on in-sample and out-of-sample \\( R^2 \\) values. The code splits the data, fits an extensive regression model with main effects and multiple interactions, and calculates \\( R^2 \\) to assess model accuracy both within (in-sample) and beyond (out-of-sample) the training data. A high out-of-sample \\( R^2 \\) close to the in-sample \\( R^2 \\) suggests good model generalization, while a much lower out-of-sample \\( R^2 \\) could indicate overfitting.\n",
    "\n",
    "link: https://chatgpt.com/share/67328c5d-6e88-800d-a4e1-34302f65803e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7826b099",
   "metadata": {},
   "source": [
    "***Question 6***\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e077fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:09:03</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Tue, 12 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     20:09:03     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        20:09:03   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Cond. No.\" WAS 343.0 WITHOUT to centering and scaling\n",
    "model3_fit.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28e7a78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:09:03</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>              <td>   69.3025</td> <td>    1.186</td> <td>   58.439</td> <td> 0.000</td> <td>   66.971</td> <td>   71.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Attack))</th>  <td>    8.1099</td> <td>    1.340</td> <td>    6.051</td> <td> 0.000</td> <td>    5.475</td> <td>   10.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Defense))</th> <td>    2.9496</td> <td>    1.340</td> <td>    2.201</td> <td> 0.028</td> <td>    0.315</td> <td>    5.585</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    1.66</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}         &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}                &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}                  & Tue, 12 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}                  &     20:09:03     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:}      &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}          &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}              &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}              &      69.3025  &        1.186     &    58.439  &         0.000        &       66.971    &       71.634     \\\\\n",
       "\\textbf{scale(center(Attack))}  &       8.1099  &        1.340     &     6.051  &         0.000        &        5.475    &       10.745     \\\\\n",
       "\\textbf{scale(center(Defense))} &       2.9496  &        1.340     &     2.201  &         0.028        &        0.315    &        5.585     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     1.66  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        20:09:03   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "Intercept                 69.3025      1.186     58.439      0.000      66.971      71.634\n",
       "scale(center(Attack))      8.1099      1.340      6.051      0.000       5.475      10.745\n",
       "scale(center(Defense))     2.9496      1.340      2.201      0.028       0.315       5.585\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         1.66\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from patsy import center, scale\n",
    "\n",
    "model3_linear_form_center_scale = \\\n",
    "  'HP ~ scale(center(Attack)) + scale(center(Defense))' \n",
    "model_spec3_center_scale = smf.ols(formula=model3_linear_form_center_scale,\n",
    "                                   data=pokeaman_train)\n",
    "model3_center_scale_fit = model_spec3_center_scale.fit()\n",
    "model3_center_scale_fit.summary()\n",
    "# \"Cond. No.\" is NOW 1.66 due to centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8027b818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.54e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.663  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.54e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Defense))'\n",
    "model4_linear_form_CS += ' * scale(center(Speed)) * Legendary' \n",
    "model4_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# Legendary is an indicator, so we don't center and scale that\n",
    "\n",
    "model4_CS_spec = smf.ols(formula=model4_linear_form_CS, data=pokeaman_train)\n",
    "model4_CS_fit = model4_CS_spec.fit()\n",
    "model4_CS_fit.summary().tables[-1]  # Cond. No. is 2,250,000,000,000,000\n",
    "\n",
    "# The condition number is still bad even after centering and scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539b8d37",
   "metadata": {},
   "source": [
    "The new model4linear model creates new predictor variables by centering each of the old predictor variables at 0 (by subtracting the mean) and then dividing the values by the standard deviation to get a standard deviation of 1. Now, we see that this model is highly colinear, which means that it cannot tell which independent variable the change in the dependent variable is caused by. Meaning that it works well for our current dataset, but won't work well on another dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0270d463",
   "metadata": {},
   "source": [
    "***Question 7***\n",
    "---\n",
    "\n",
    "Model5_linear_form is an extended version of model3_linear_fit and model4_linear_fit by adding the predictor categorical variables: \"Generation\", \"Type 1\", and \"Type 2\". These factors are included in Model5_linear_form, as it is likely that a pokemon's HP is connected with it's type and generation. \n",
    "\n",
    "model6_linear_form is further extended from model5_linear_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23a43262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>9.48e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:09:04</td>     <th>  Log-Likelihood:    </th> <td> -1765.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3624.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   353</td>      <th>  BIC:               </th> <td>   3812.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    46</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>   10.1046</td> <td>   14.957</td> <td>    0.676</td> <td> 0.500</td> <td>  -19.312</td> <td>   39.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>          <td>   -3.2717</td> <td>    4.943</td> <td>   -0.662</td> <td> 0.508</td> <td>  -12.992</td> <td>    6.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>         <td>    9.2938</td> <td>    4.015</td> <td>    2.315</td> <td> 0.021</td> <td>    1.398</td> <td>   17.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>         <td>    2.3150</td> <td>    3.915</td> <td>    0.591</td> <td> 0.555</td> <td>   -5.385</td> <td>   10.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>         <td>    4.8353</td> <td>    4.149</td> <td>    1.165</td> <td> 0.245</td> <td>   -3.325</td> <td>   12.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>         <td>   11.4838</td> <td>    3.960</td> <td>    2.900</td> <td> 0.004</td> <td>    3.696</td> <td>   19.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>         <td>    4.9206</td> <td>    4.746</td> <td>    1.037</td> <td> 0.300</td> <td>   -4.413</td> <td>   14.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Dark]</th>     <td>   -1.4155</td> <td>    6.936</td> <td>   -0.204</td> <td> 0.838</td> <td>  -15.057</td> <td>   12.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Dragon]</th>   <td>    0.8509</td> <td>    6.900</td> <td>    0.123</td> <td> 0.902</td> <td>  -12.720</td> <td>   14.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Electric]</th> <td>   -6.3641</td> <td>    6.537</td> <td>   -0.974</td> <td> 0.331</td> <td>  -19.220</td> <td>    6.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fairy]</th>    <td>   -1.9486</td> <td>   10.124</td> <td>   -0.192</td> <td> 0.847</td> <td>  -21.859</td> <td>   17.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fighting]</th> <td>    7.0308</td> <td>    7.432</td> <td>    0.946</td> <td> 0.345</td> <td>   -7.586</td> <td>   21.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fire]</th>     <td>    3.0779</td> <td>    6.677</td> <td>    0.461</td> <td> 0.645</td> <td>  -10.055</td> <td>   16.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Flying]</th>   <td>   -2.1231</td> <td>   22.322</td> <td>   -0.095</td> <td> 0.924</td> <td>  -46.025</td> <td>   41.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ghost]</th>    <td>    5.7343</td> <td>    8.488</td> <td>    0.676</td> <td> 0.500</td> <td>  -10.960</td> <td>   22.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Grass]</th>    <td>    3.3275</td> <td>    5.496</td> <td>    0.605</td> <td> 0.545</td> <td>   -7.481</td> <td>   14.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ground]</th>   <td>    9.5118</td> <td>    7.076</td> <td>    1.344</td> <td> 0.180</td> <td>   -4.404</td> <td>   23.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ice]</th>      <td>   -0.9313</td> <td>    7.717</td> <td>   -0.121</td> <td> 0.904</td> <td>  -16.108</td> <td>   14.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Normal]</th>   <td>   18.4816</td> <td>    5.312</td> <td>    3.479</td> <td> 0.001</td> <td>    8.034</td> <td>   28.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Poison]</th>   <td>    8.3411</td> <td>    7.735</td> <td>    1.078</td> <td> 0.282</td> <td>   -6.871</td> <td>   23.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Psychic]</th>  <td>    1.8061</td> <td>    6.164</td> <td>    0.293</td> <td> 0.770</td> <td>  -10.317</td> <td>   13.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Rock]</th>     <td>   -3.8558</td> <td>    6.503</td> <td>   -0.593</td> <td> 0.554</td> <td>  -16.645</td> <td>    8.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Steel]</th>    <td>   -4.0053</td> <td>    8.044</td> <td>   -0.498</td> <td> 0.619</td> <td>  -19.826</td> <td>   11.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Water]</th>    <td>    9.7988</td> <td>    5.166</td> <td>    1.897</td> <td> 0.059</td> <td>   -0.361</td> <td>   19.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Dark]</th>     <td>    5.8719</td> <td>   15.185</td> <td>    0.387</td> <td> 0.699</td> <td>  -23.993</td> <td>   35.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Dragon]</th>   <td>   13.2777</td> <td>   14.895</td> <td>    0.891</td> <td> 0.373</td> <td>  -16.016</td> <td>   42.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Electric]</th> <td>   14.3228</td> <td>   17.314</td> <td>    0.827</td> <td> 0.409</td> <td>  -19.728</td> <td>   48.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fairy]</th>    <td>    2.8426</td> <td>   14.268</td> <td>    0.199</td> <td> 0.842</td> <td>  -25.218</td> <td>   30.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fighting]</th> <td>    1.9741</td> <td>   14.089</td> <td>    0.140</td> <td> 0.889</td> <td>  -25.735</td> <td>   29.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fire]</th>     <td>    0.2001</td> <td>   15.730</td> <td>    0.013</td> <td> 0.990</td> <td>  -30.736</td> <td>   31.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Flying]</th>   <td>    6.7292</td> <td>   13.581</td> <td>    0.495</td> <td> 0.621</td> <td>  -19.980</td> <td>   33.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ghost]</th>    <td>  -10.9402</td> <td>   15.895</td> <td>   -0.688</td> <td> 0.492</td> <td>  -42.201</td> <td>   20.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Grass]</th>    <td>    2.5119</td> <td>   14.540</td> <td>    0.173</td> <td> 0.863</td> <td>  -26.084</td> <td>   31.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ground]</th>   <td>   13.6042</td> <td>   13.655</td> <td>    0.996</td> <td> 0.320</td> <td>  -13.250</td> <td>   40.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ice]</th>      <td>   19.7950</td> <td>   15.068</td> <td>    1.314</td> <td> 0.190</td> <td>   -9.840</td> <td>   49.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.None]</th>     <td>    7.6068</td> <td>   13.162</td> <td>    0.578</td> <td> 0.564</td> <td>  -18.279</td> <td>   33.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Normal]</th>   <td>   17.3191</td> <td>   17.764</td> <td>    0.975</td> <td> 0.330</td> <td>  -17.618</td> <td>   52.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Poison]</th>   <td>    0.7770</td> <td>   14.575</td> <td>    0.053</td> <td> 0.958</td> <td>  -27.887</td> <td>   29.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Psychic]</th>  <td>    4.2480</td> <td>   14.174</td> <td>    0.300</td> <td> 0.765</td> <td>  -23.628</td> <td>   32.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Rock]</th>     <td>    6.8858</td> <td>   16.221</td> <td>    0.424</td> <td> 0.671</td> <td>  -25.017</td> <td>   38.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Steel]</th>    <td>  -11.9623</td> <td>   14.973</td> <td>   -0.799</td> <td> 0.425</td> <td>  -41.409</td> <td>   17.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Water]</th>    <td>    5.8097</td> <td>   14.763</td> <td>    0.394</td> <td> 0.694</td> <td>  -23.225</td> <td>   34.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                     <td>    0.2508</td> <td>    0.051</td> <td>    4.940</td> <td> 0.000</td> <td>    0.151</td> <td>    0.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                    <td>   -0.0096</td> <td>    0.060</td> <td>   -0.160</td> <td> 0.873</td> <td>   -0.127</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                      <td>   -0.1538</td> <td>    0.051</td> <td>   -2.998</td> <td> 0.003</td> <td>   -0.255</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>               <td>    0.3484</td> <td>    0.059</td> <td>    5.936</td> <td> 0.000</td> <td>    0.233</td> <td>    0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>               <td>    0.1298</td> <td>    0.051</td> <td>    2.525</td> <td> 0.012</td> <td>    0.029</td> <td>    0.231</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>286.476</td> <th>  Durbin-Watson:     </th> <td>   1.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5187.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.807</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>19.725</td>  <th>  Cond. No.          </th> <td>9.21e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 9.21e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}             &        HP        & \\textbf{  R-squared:         } &     0.392   \\\\\n",
       "\\textbf{Model:}                     &       OLS        & \\textbf{  Adj. R-squared:    } &     0.313   \\\\\n",
       "\\textbf{Method:}                    &  Least Squares   & \\textbf{  F-statistic:       } &     4.948   \\\\\n",
       "\\textbf{Date:}                      & Tue, 12 Nov 2024 & \\textbf{  Prob (F-statistic):} &  9.48e-19   \\\\\n",
       "\\textbf{Time:}                      &     20:09:04     & \\textbf{  Log-Likelihood:    } &   -1765.0   \\\\\n",
       "\\textbf{No. Observations:}          &         400      & \\textbf{  AIC:               } &     3624.   \\\\\n",
       "\\textbf{Df Residuals:}              &         353      & \\textbf{  BIC:               } &     3812.   \\\\\n",
       "\\textbf{Df Model:}                  &          46      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}           &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                    & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                  &      10.1046  &       14.957     &     0.676  &         0.500        &      -19.312    &       39.521     \\\\\n",
       "\\textbf{Legendary[T.True]}          &      -3.2717  &        4.943     &    -0.662  &         0.508        &      -12.992    &        6.449     \\\\\n",
       "\\textbf{C(Generation)[T.2]}         &       9.2938  &        4.015     &     2.315  &         0.021        &        1.398    &       17.189     \\\\\n",
       "\\textbf{C(Generation)[T.3]}         &       2.3150  &        3.915     &     0.591  &         0.555        &       -5.385    &       10.015     \\\\\n",
       "\\textbf{C(Generation)[T.4]}         &       4.8353  &        4.149     &     1.165  &         0.245        &       -3.325    &       12.995     \\\\\n",
       "\\textbf{C(Generation)[T.5]}         &      11.4838  &        3.960     &     2.900  &         0.004        &        3.696    &       19.272     \\\\\n",
       "\\textbf{C(Generation)[T.6]}         &       4.9206  &        4.746     &     1.037  &         0.300        &       -4.413    &       14.254     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Dark]}     &      -1.4155  &        6.936     &    -0.204  &         0.838        &      -15.057    &       12.226     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Dragon]}   &       0.8509  &        6.900     &     0.123  &         0.902        &      -12.720    &       14.422     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Electric]} &      -6.3641  &        6.537     &    -0.974  &         0.331        &      -19.220    &        6.491     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fairy]}    &      -1.9486  &       10.124     &    -0.192  &         0.847        &      -21.859    &       17.962     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fighting]} &       7.0308  &        7.432     &     0.946  &         0.345        &       -7.586    &       21.648     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fire]}     &       3.0779  &        6.677     &     0.461  &         0.645        &      -10.055    &       16.210     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Flying]}   &      -2.1231  &       22.322     &    -0.095  &         0.924        &      -46.025    &       41.779     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ghost]}    &       5.7343  &        8.488     &     0.676  &         0.500        &      -10.960    &       22.429     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Grass]}    &       3.3275  &        5.496     &     0.605  &         0.545        &       -7.481    &       14.136     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ground]}   &       9.5118  &        7.076     &     1.344  &         0.180        &       -4.404    &       23.428     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ice]}      &      -0.9313  &        7.717     &    -0.121  &         0.904        &      -16.108    &       14.246     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Normal]}   &      18.4816  &        5.312     &     3.479  &         0.001        &        8.034    &       28.929     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Poison]}   &       8.3411  &        7.735     &     1.078  &         0.282        &       -6.871    &       23.554     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Psychic]}  &       1.8061  &        6.164     &     0.293  &         0.770        &      -10.317    &       13.930     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Rock]}     &      -3.8558  &        6.503     &    -0.593  &         0.554        &      -16.645    &        8.933     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Steel]}    &      -4.0053  &        8.044     &    -0.498  &         0.619        &      -19.826    &       11.816     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Water]}    &       9.7988  &        5.166     &     1.897  &         0.059        &       -0.361    &       19.959     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Dark]}     &       5.8719  &       15.185     &     0.387  &         0.699        &      -23.993    &       35.737     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Dragon]}   &      13.2777  &       14.895     &     0.891  &         0.373        &      -16.016    &       42.571     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Electric]} &      14.3228  &       17.314     &     0.827  &         0.409        &      -19.728    &       48.374     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fairy]}    &       2.8426  &       14.268     &     0.199  &         0.842        &      -25.218    &       30.903     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fighting]} &       1.9741  &       14.089     &     0.140  &         0.889        &      -25.735    &       29.683     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fire]}     &       0.2001  &       15.730     &     0.013  &         0.990        &      -30.736    &       31.136     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Flying]}   &       6.7292  &       13.581     &     0.495  &         0.621        &      -19.980    &       33.438     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ghost]}    &     -10.9402  &       15.895     &    -0.688  &         0.492        &      -42.201    &       20.321     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Grass]}    &       2.5119  &       14.540     &     0.173  &         0.863        &      -26.084    &       31.108     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ground]}   &      13.6042  &       13.655     &     0.996  &         0.320        &      -13.250    &       40.459     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ice]}      &      19.7950  &       15.068     &     1.314  &         0.190        &       -9.840    &       49.430     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.None]}     &       7.6068  &       13.162     &     0.578  &         0.564        &      -18.279    &       33.493     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Normal]}   &      17.3191  &       17.764     &     0.975  &         0.330        &      -17.618    &       52.256     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Poison]}   &       0.7770  &       14.575     &     0.053  &         0.958        &      -27.887    &       29.441     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Psychic]}  &       4.2480  &       14.174     &     0.300  &         0.765        &      -23.628    &       32.124     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Rock]}     &       6.8858  &       16.221     &     0.424  &         0.671        &      -25.017    &       38.788     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Steel]}    &     -11.9623  &       14.973     &    -0.799  &         0.425        &      -41.409    &       17.485     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Water]}    &       5.8097  &       14.763     &     0.394  &         0.694        &      -23.225    &       34.845     \\\\\n",
       "\\textbf{Attack}                     &       0.2508  &        0.051     &     4.940  &         0.000        &        0.151    &        0.351     \\\\\n",
       "\\textbf{Defense}                    &      -0.0096  &        0.060     &    -0.160  &         0.873        &       -0.127    &        0.108     \\\\\n",
       "\\textbf{Speed}                      &      -0.1538  &        0.051     &    -2.998  &         0.003        &       -0.255    &       -0.053     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}               &       0.3484  &        0.059     &     5.936  &         0.000        &        0.233    &        0.464     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}               &       0.1298  &        0.051     &     2.525  &         0.012        &        0.029    &        0.231     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 286.476 & \\textbf{  Durbin-Watson:     } &    1.917  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5187.327  \\\\\n",
       "\\textbf{Skew:}          &   2.807 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  19.725 & \\textbf{  Cond. No.          } & 9.21e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 9.21e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.392\n",
       "Model:                            OLS   Adj. R-squared:                  0.313\n",
       "Method:                 Least Squares   F-statistic:                     4.948\n",
       "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           9.48e-19\n",
       "Time:                        20:09:04   Log-Likelihood:                -1765.0\n",
       "No. Observations:                 400   AIC:                             3624.\n",
       "Df Residuals:                     353   BIC:                             3812.\n",
       "Df Model:                          46                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Intercept                     10.1046     14.957      0.676      0.500     -19.312      39.521\n",
       "Legendary[T.True]             -3.2717      4.943     -0.662      0.508     -12.992       6.449\n",
       "C(Generation)[T.2]             9.2938      4.015      2.315      0.021       1.398      17.189\n",
       "C(Generation)[T.3]             2.3150      3.915      0.591      0.555      -5.385      10.015\n",
       "C(Generation)[T.4]             4.8353      4.149      1.165      0.245      -3.325      12.995\n",
       "C(Generation)[T.5]            11.4838      3.960      2.900      0.004       3.696      19.272\n",
       "C(Generation)[T.6]             4.9206      4.746      1.037      0.300      -4.413      14.254\n",
       "C(Q(\"Type 1\"))[T.Dark]        -1.4155      6.936     -0.204      0.838     -15.057      12.226\n",
       "C(Q(\"Type 1\"))[T.Dragon]       0.8509      6.900      0.123      0.902     -12.720      14.422\n",
       "C(Q(\"Type 1\"))[T.Electric]    -6.3641      6.537     -0.974      0.331     -19.220       6.491\n",
       "C(Q(\"Type 1\"))[T.Fairy]       -1.9486     10.124     -0.192      0.847     -21.859      17.962\n",
       "C(Q(\"Type 1\"))[T.Fighting]     7.0308      7.432      0.946      0.345      -7.586      21.648\n",
       "C(Q(\"Type 1\"))[T.Fire]         3.0779      6.677      0.461      0.645     -10.055      16.210\n",
       "C(Q(\"Type 1\"))[T.Flying]      -2.1231     22.322     -0.095      0.924     -46.025      41.779\n",
       "C(Q(\"Type 1\"))[T.Ghost]        5.7343      8.488      0.676      0.500     -10.960      22.429\n",
       "C(Q(\"Type 1\"))[T.Grass]        3.3275      5.496      0.605      0.545      -7.481      14.136\n",
       "C(Q(\"Type 1\"))[T.Ground]       9.5118      7.076      1.344      0.180      -4.404      23.428\n",
       "C(Q(\"Type 1\"))[T.Ice]         -0.9313      7.717     -0.121      0.904     -16.108      14.246\n",
       "C(Q(\"Type 1\"))[T.Normal]      18.4816      5.312      3.479      0.001       8.034      28.929\n",
       "C(Q(\"Type 1\"))[T.Poison]       8.3411      7.735      1.078      0.282      -6.871      23.554\n",
       "C(Q(\"Type 1\"))[T.Psychic]      1.8061      6.164      0.293      0.770     -10.317      13.930\n",
       "C(Q(\"Type 1\"))[T.Rock]        -3.8558      6.503     -0.593      0.554     -16.645       8.933\n",
       "C(Q(\"Type 1\"))[T.Steel]       -4.0053      8.044     -0.498      0.619     -19.826      11.816\n",
       "C(Q(\"Type 1\"))[T.Water]        9.7988      5.166      1.897      0.059      -0.361      19.959\n",
       "C(Q(\"Type 2\"))[T.Dark]         5.8719     15.185      0.387      0.699     -23.993      35.737\n",
       "C(Q(\"Type 2\"))[T.Dragon]      13.2777     14.895      0.891      0.373     -16.016      42.571\n",
       "C(Q(\"Type 2\"))[T.Electric]    14.3228     17.314      0.827      0.409     -19.728      48.374\n",
       "C(Q(\"Type 2\"))[T.Fairy]        2.8426     14.268      0.199      0.842     -25.218      30.903\n",
       "C(Q(\"Type 2\"))[T.Fighting]     1.9741     14.089      0.140      0.889     -25.735      29.683\n",
       "C(Q(\"Type 2\"))[T.Fire]         0.2001     15.730      0.013      0.990     -30.736      31.136\n",
       "C(Q(\"Type 2\"))[T.Flying]       6.7292     13.581      0.495      0.621     -19.980      33.438\n",
       "C(Q(\"Type 2\"))[T.Ghost]      -10.9402     15.895     -0.688      0.492     -42.201      20.321\n",
       "C(Q(\"Type 2\"))[T.Grass]        2.5119     14.540      0.173      0.863     -26.084      31.108\n",
       "C(Q(\"Type 2\"))[T.Ground]      13.6042     13.655      0.996      0.320     -13.250      40.459\n",
       "C(Q(\"Type 2\"))[T.Ice]         19.7950     15.068      1.314      0.190      -9.840      49.430\n",
       "C(Q(\"Type 2\"))[T.None]         7.6068     13.162      0.578      0.564     -18.279      33.493\n",
       "C(Q(\"Type 2\"))[T.Normal]      17.3191     17.764      0.975      0.330     -17.618      52.256\n",
       "C(Q(\"Type 2\"))[T.Poison]       0.7770     14.575      0.053      0.958     -27.887      29.441\n",
       "C(Q(\"Type 2\"))[T.Psychic]      4.2480     14.174      0.300      0.765     -23.628      32.124\n",
       "C(Q(\"Type 2\"))[T.Rock]         6.8858     16.221      0.424      0.671     -25.017      38.788\n",
       "C(Q(\"Type 2\"))[T.Steel]      -11.9623     14.973     -0.799      0.425     -41.409      17.485\n",
       "C(Q(\"Type 2\"))[T.Water]        5.8097     14.763      0.394      0.694     -23.225      34.845\n",
       "Attack                         0.2508      0.051      4.940      0.000       0.151       0.351\n",
       "Defense                       -0.0096      0.060     -0.160      0.873      -0.127       0.108\n",
       "Speed                         -0.1538      0.051     -2.998      0.003      -0.255      -0.053\n",
       "Q(\"Sp. Def\")                   0.3484      0.059      5.936      0.000       0.233       0.464\n",
       "Q(\"Sp. Atk\")                   0.1298      0.051      2.525      0.012       0.029       0.231\n",
       "==============================================================================\n",
       "Omnibus:                      286.476   Durbin-Watson:                   1.917\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5187.327\n",
       "Skew:                           2.807   Prob(JB):                         0.00\n",
       "Kurtosis:                      19.725   Cond. No.                     9.21e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.21e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model5_linear_form = 'HP ~ Attack + Defense + Speed + Legendary'\n",
    "model5_linear_form += ' + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "model5_linear_form += ' + C(Generation) + C(Q(\"Type 1\")) + C(Q(\"Type 2\"))'\n",
    "\n",
    "model5_spec = smf.ols(formula=model5_linear_form, data=pokeaman_train)\n",
    "model5_fit = model5_spec.fit()\n",
    "model5_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22fbc040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3920134083531893\n",
      "'Out of sample' R-squared: 0.30015614488652215\n"
     ]
    }
   ],
   "source": [
    "yhat_model5 = model5_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model5_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model5)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e955992a",
   "metadata": {},
   "source": [
    "This appears to help reduce multicolinearity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cdfed24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   24.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>2.25e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:09:05</td>     <th>  Log-Likelihood:    </th> <td> -1783.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3585.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   391</td>      <th>  BIC:               </th> <td>   3621.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                   <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                          <td>   22.8587</td> <td>    3.876</td> <td>    5.897</td> <td> 0.000</td> <td>   15.238</td> <td>   30.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Normal\")[T.True]</th> <td>   17.5594</td> <td>    3.339</td> <td>    5.258</td> <td> 0.000</td> <td>   10.994</td> <td>   24.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Water\")[T.True]</th>  <td>    9.0301</td> <td>    3.172</td> <td>    2.847</td> <td> 0.005</td> <td>    2.794</td> <td>   15.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 2)[T.True]</th>         <td>    6.5293</td> <td>    2.949</td> <td>    2.214</td> <td> 0.027</td> <td>    0.732</td> <td>   12.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 5)[T.True]</th>         <td>    8.4406</td> <td>    2.711</td> <td>    3.114</td> <td> 0.002</td> <td>    3.112</td> <td>   13.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                             <td>    0.2454</td> <td>    0.037</td> <td>    6.639</td> <td> 0.000</td> <td>    0.173</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                              <td>   -0.1370</td> <td>    0.045</td> <td>   -3.028</td> <td> 0.003</td> <td>   -0.226</td> <td>   -0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                       <td>    0.3002</td> <td>    0.045</td> <td>    6.662</td> <td> 0.000</td> <td>    0.212</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                       <td>    0.1192</td> <td>    0.042</td> <td>    2.828</td> <td> 0.005</td> <td>    0.036</td> <td>    0.202</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>271.290</td> <th>  Durbin-Watson:     </th> <td>   1.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4238.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.651</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>18.040</td>  <th>  Cond. No.          </th> <td>    618.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                     &        HP        & \\textbf{  R-squared:         } &     0.333   \\\\\n",
       "\\textbf{Model:}                             &       OLS        & \\textbf{  Adj. R-squared:    } &     0.319   \\\\\n",
       "\\textbf{Method:}                            &  Least Squares   & \\textbf{  F-statistic:       } &     24.36   \\\\\n",
       "\\textbf{Date:}                              & Tue, 12 Nov 2024 & \\textbf{  Prob (F-statistic):} &  2.25e-30   \\\\\n",
       "\\textbf{Time:}                              &     20:09:05     & \\textbf{  Log-Likelihood:    } &   -1783.6   \\\\\n",
       "\\textbf{No. Observations:}                  &         400      & \\textbf{  AIC:               } &     3585.   \\\\\n",
       "\\textbf{Df Residuals:}                      &         391      & \\textbf{  BIC:               } &     3621.   \\\\\n",
       "\\textbf{Df Model:}                          &           8      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                   &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                            & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                          &      22.8587  &        3.876     &     5.897  &         0.000        &       15.238    &       30.479     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Normal\")[T.True]} &      17.5594  &        3.339     &     5.258  &         0.000        &       10.994    &       24.125     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Water\")[T.True]}  &       9.0301  &        3.172     &     2.847  &         0.005        &        2.794    &       15.266     \\\\\n",
       "\\textbf{I(Generation == 2)[T.True]}         &       6.5293  &        2.949     &     2.214  &         0.027        &        0.732    &       12.327     \\\\\n",
       "\\textbf{I(Generation == 5)[T.True]}         &       8.4406  &        2.711     &     3.114  &         0.002        &        3.112    &       13.770     \\\\\n",
       "\\textbf{Attack}                             &       0.2454  &        0.037     &     6.639  &         0.000        &        0.173    &        0.318     \\\\\n",
       "\\textbf{Speed}                              &      -0.1370  &        0.045     &    -3.028  &         0.003        &       -0.226    &       -0.048     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                       &       0.3002  &        0.045     &     6.662  &         0.000        &        0.212    &        0.389     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                       &       0.1192  &        0.042     &     2.828  &         0.005        &        0.036    &        0.202     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 271.290 & \\textbf{  Durbin-Watson:     } &    1.999  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 4238.692  \\\\\n",
       "\\textbf{Skew:}          &   2.651 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  18.040 & \\textbf{  Cond. No.          } &     618.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.333\n",
       "Model:                            OLS   Adj. R-squared:                  0.319\n",
       "Method:                 Least Squares   F-statistic:                     24.36\n",
       "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           2.25e-30\n",
       "Time:                        20:09:05   Log-Likelihood:                -1783.6\n",
       "No. Observations:                 400   AIC:                             3585.\n",
       "Df Residuals:                     391   BIC:                             3621.\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================================\n",
       "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------\n",
       "Intercept                             22.8587      3.876      5.897      0.000      15.238      30.479\n",
       "I(Q(\"Type 1\") == \"Normal\")[T.True]    17.5594      3.339      5.258      0.000      10.994      24.125\n",
       "I(Q(\"Type 1\") == \"Water\")[T.True]      9.0301      3.172      2.847      0.005       2.794      15.266\n",
       "I(Generation == 2)[T.True]             6.5293      2.949      2.214      0.027       0.732      12.327\n",
       "I(Generation == 5)[T.True]             8.4406      2.711      3.114      0.002       3.112      13.770\n",
       "Attack                                 0.2454      0.037      6.639      0.000       0.173       0.318\n",
       "Speed                                 -0.1370      0.045     -3.028      0.003      -0.226      -0.048\n",
       "Q(\"Sp. Def\")                           0.3002      0.045      6.662      0.000       0.212       0.389\n",
       "Q(\"Sp. Atk\")                           0.1192      0.042      2.828      0.005       0.036       0.202\n",
       "==============================================================================\n",
       "Omnibus:                      271.290   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4238.692\n",
       "Skew:                           2.651   Prob(JB):                         0.00\n",
       "Kurtosis:                      18.040   Cond. No.                         618.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model6_linear_form = 'HP ~ Attack + Speed + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "# And here we'll add the significant indicators from the previous model\n",
    "# https://chatgpt.com/share/81ab88df-4f07-49f9-a44a-de0cfd89c67c\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model6_linear_form += ' + I(Generation==2)'\n",
    "model6_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model6_spec = smf.ols(formula=model6_linear_form, data=pokeaman_train)\n",
    "model6_fit = model6_spec.fit()\n",
    "model6_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b6799",
   "metadata": {},
   "source": [
    "Next, model6_linear_form is extended from model5_linear_form, by turning the statistically significant predictor variables (Type1 = Water, Type1 = normal, Generation = 2, Generation = 5) into indicator variables rather than the continuous predictor variables they were before. This clearly illustrates the change in HP that a pokemon may have when it triggers one of these indicator variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d670f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908\n",
      "'Out of sample' R-squared: 0.29572460427079933\n"
     ]
    }
   ],
   "source": [
    "yhat_model6 = model6_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fb002d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.20e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:09:05</td>     <th>  Log-Likelihood:    </th> <td> -1769.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3579.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   380</td>      <th>  BIC:               </th> <td>   3659.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                     <td></td>                       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                              <td>   95.1698</td> <td>   34.781</td> <td>    2.736</td> <td> 0.007</td> <td>   26.783</td> <td>  163.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Normal\")[T.True]</th>     <td>   18.3653</td> <td>    3.373</td> <td>    5.445</td> <td> 0.000</td> <td>   11.733</td> <td>   24.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Water\")[T.True]</th>      <td>    9.2913</td> <td>    3.140</td> <td>    2.959</td> <td> 0.003</td> <td>    3.117</td> <td>   15.466</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 2)[T.True]</th>             <td>    7.0711</td> <td>    2.950</td> <td>    2.397</td> <td> 0.017</td> <td>    1.271</td> <td>   12.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 5)[T.True]</th>             <td>    7.8557</td> <td>    2.687</td> <td>    2.923</td> <td> 0.004</td> <td>    2.572</td> <td>   13.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                 <td>   -0.6975</td> <td>    0.458</td> <td>   -1.523</td> <td> 0.129</td> <td>   -1.598</td> <td>    0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                  <td>   -1.8147</td> <td>    0.554</td> <td>   -3.274</td> <td> 0.001</td> <td>   -2.905</td> <td>   -0.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                           <td>    0.0189</td> <td>    0.007</td> <td>    2.882</td> <td> 0.004</td> <td>    0.006</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                           <td>   -0.5532</td> <td>    0.546</td> <td>   -1.013</td> <td> 0.312</td> <td>   -1.627</td> <td>    0.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                    <td>    0.0090</td> <td>    0.007</td> <td>    1.311</td> <td> 0.191</td> <td>   -0.004</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                     <td>    0.0208</td> <td>    0.008</td> <td>    2.571</td> <td> 0.011</td> <td>    0.005</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>              <td>   -0.0002</td> <td> 9.06e-05</td> <td>   -2.277</td> <td> 0.023</td> <td>   -0.000</td> <td>-2.82e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                           <td>   -0.7277</td> <td>    0.506</td> <td>   -1.439</td> <td> 0.151</td> <td>   -1.722</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                    <td>    0.0136</td> <td>    0.005</td> <td>    2.682</td> <td> 0.008</td> <td>    0.004</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                     <td>    0.0146</td> <td>    0.007</td> <td>    2.139</td> <td> 0.033</td> <td>    0.001</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>              <td>   -0.0002</td> <td>  5.4e-05</td> <td>   -3.383</td> <td> 0.001</td> <td>   -0.000</td> <td>-7.65e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0103</td> <td>    0.007</td> <td>    1.516</td> <td> 0.130</td> <td>   -0.003</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>   -0.0001</td> <td> 6.71e-05</td> <td>   -2.119</td> <td> 0.035</td> <td>   -0.000</td> <td>-1.03e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0002</td> <td> 8.82e-05</td> <td>   -2.075</td> <td> 0.039</td> <td>   -0.000</td> <td>-9.62e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>  2.03e-06</td> <td> 7.42e-07</td> <td>    2.734</td> <td> 0.007</td> <td>  5.7e-07</td> <td> 3.49e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>2.34e+09</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.34e+09. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                         &        HP        & \\textbf{  R-squared:         } &     0.378   \\\\\n",
       "\\textbf{Model:}                                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.347   \\\\\n",
       "\\textbf{Method:}                                &  Least Squares   & \\textbf{  F-statistic:       } &     12.16   \\\\\n",
       "\\textbf{Date:}                                  & Tue, 12 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.20e-29   \\\\\n",
       "\\textbf{Time:}                                  &     20:09:05     & \\textbf{  Log-Likelihood:    } &   -1769.5   \\\\\n",
       "\\textbf{No. Observations:}                      &         400      & \\textbf{  AIC:               } &     3579.   \\\\\n",
       "\\textbf{Df Residuals:}                          &         380      & \\textbf{  BIC:               } &     3659.   \\\\\n",
       "\\textbf{Df Model:}                              &          19      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                              &      95.1698  &       34.781     &     2.736  &         0.007        &       26.783    &      163.556     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Normal\")[T.True]}     &      18.3653  &        3.373     &     5.445  &         0.000        &       11.733    &       24.997     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Water\")[T.True]}      &       9.2913  &        3.140     &     2.959  &         0.003        &        3.117    &       15.466     \\\\\n",
       "\\textbf{I(Generation == 2)[T.True]}             &       7.0711  &        2.950     &     2.397  &         0.017        &        1.271    &       12.871     \\\\\n",
       "\\textbf{I(Generation == 5)[T.True]}             &       7.8557  &        2.687     &     2.923  &         0.004        &        2.572    &       13.140     \\\\\n",
       "\\textbf{Attack}                                 &      -0.6975  &        0.458     &    -1.523  &         0.129        &       -1.598    &        0.203     \\\\\n",
       "\\textbf{Speed}                                  &      -1.8147  &        0.554     &    -3.274  &         0.001        &       -2.905    &       -0.725     \\\\\n",
       "\\textbf{Attack:Speed}                           &       0.0189  &        0.007     &     2.882  &         0.004        &        0.006    &        0.032     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                           &      -0.5532  &        0.546     &    -1.013  &         0.312        &       -1.627    &        0.521     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                    &       0.0090  &        0.007     &     1.311  &         0.191        &       -0.004    &        0.023     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                     &       0.0208  &        0.008     &     2.571  &         0.011        &        0.005    &        0.037     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}              &      -0.0002  &     9.06e-05     &    -2.277  &         0.023        &       -0.000    &    -2.82e-05     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                           &      -0.7277  &        0.506     &    -1.439  &         0.151        &       -1.722    &        0.267     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                    &       0.0136  &        0.005     &     2.682  &         0.008        &        0.004    &        0.024     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                     &       0.0146  &        0.007     &     2.139  &         0.033        &        0.001    &        0.028     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}              &      -0.0002  &      5.4e-05     &    -3.383  &         0.001        &       -0.000    &    -7.65e-05     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0103  &        0.007     &     1.516  &         0.130        &       -0.003    &        0.024     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &      -0.0001  &     6.71e-05     &    -2.119  &         0.035        &       -0.000    &    -1.03e-05     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0002  &     8.82e-05     &    -2.075  &         0.039        &       -0.000    &    -9.62e-06     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &     2.03e-06  &     7.42e-07     &     2.734  &         0.007        &      5.7e-07    &     3.49e-06     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } & 2.34e+09  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.34e+09. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.378\n",
       "Model:                            OLS   Adj. R-squared:                  0.347\n",
       "Method:                 Least Squares   F-statistic:                     12.16\n",
       "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           4.20e-29\n",
       "Time:                        20:09:05   Log-Likelihood:                -1769.5\n",
       "No. Observations:                 400   AIC:                             3579.\n",
       "Df Residuals:                     380   BIC:                             3659.\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================================\n",
       "                                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------------\n",
       "Intercept                                 95.1698     34.781      2.736      0.007      26.783     163.556\n",
       "I(Q(\"Type 1\") == \"Normal\")[T.True]        18.3653      3.373      5.445      0.000      11.733      24.997\n",
       "I(Q(\"Type 1\") == \"Water\")[T.True]          9.2913      3.140      2.959      0.003       3.117      15.466\n",
       "I(Generation == 2)[T.True]                 7.0711      2.950      2.397      0.017       1.271      12.871\n",
       "I(Generation == 5)[T.True]                 7.8557      2.687      2.923      0.004       2.572      13.140\n",
       "Attack                                    -0.6975      0.458     -1.523      0.129      -1.598       0.203\n",
       "Speed                                     -1.8147      0.554     -3.274      0.001      -2.905      -0.725\n",
       "Attack:Speed                               0.0189      0.007      2.882      0.004       0.006       0.032\n",
       "Q(\"Sp. Def\")                              -0.5532      0.546     -1.013      0.312      -1.627       0.521\n",
       "Attack:Q(\"Sp. Def\")                        0.0090      0.007      1.311      0.191      -0.004       0.023\n",
       "Speed:Q(\"Sp. Def\")                         0.0208      0.008      2.571      0.011       0.005       0.037\n",
       "Attack:Speed:Q(\"Sp. Def\")                 -0.0002   9.06e-05     -2.277      0.023      -0.000   -2.82e-05\n",
       "Q(\"Sp. Atk\")                              -0.7277      0.506     -1.439      0.151      -1.722       0.267\n",
       "Attack:Q(\"Sp. Atk\")                        0.0136      0.005      2.682      0.008       0.004       0.024\n",
       "Speed:Q(\"Sp. Atk\")                         0.0146      0.007      2.139      0.033       0.001       0.028\n",
       "Attack:Speed:Q(\"Sp. Atk\")                 -0.0002    5.4e-05     -3.383      0.001      -0.000   -7.65e-05\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0103      0.007      1.516      0.130      -0.003       0.024\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          -0.0001   6.71e-05     -2.119      0.035      -0.000   -1.03e-05\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0002   8.82e-05     -2.075      0.039      -0.000   -9.62e-06\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")   2.03e-06   7.42e-07      2.734      0.007     5.7e-07    3.49e-06\n",
       "==============================================================================\n",
       "Omnibus:                      252.300   Durbin-Watson:                   1.953\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3474.611\n",
       "Skew:                           2.438   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.590   Cond. No.                     2.34e+09\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.34e+09. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here's a slight change that seems to perhaps improve prediction...\n",
    "model7_linear_form = 'HP ~ Attack * Speed * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form += ' + I(Generation==2)'\n",
    "model7_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model7_spec = smf.ols(formula=model7_linear_form, data=pokeaman_train)\n",
    "model7_fit = model7_spec.fit()\n",
    "model7_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85105a3b",
   "metadata": {},
   "source": [
    "Model7_linear_form, now takes into account the interaction between the seperate predictor variables. It now shows how the inclusion of multiple variables changes the HP. This allows the model to account for more complex relationships betwen the predictor variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "583dd18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456\n",
      "'Out of sample' R-squared: 0.35055389205977444\n"
     ]
    }
   ],
   "source": [
    "yhat_model7 = model7_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f0819b",
   "metadata": {},
   "source": [
    "Finally, we center all predictor variables to try and reduce multicolinearity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cba033fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>    15.4</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } &     15.4  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# And here's a slight change that seems to perhas improve prediction...\n",
    "model7_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Speed))'\n",
    "model7_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# We DO NOT center and scale indicator variables\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form_CS += ' + I(Generation==2)'\n",
    "model7_linear_form_CS += ' + I(Generation==5)'\n",
    "\n",
    "model7_CS_spec = smf.ols(formula=model7_linear_form_CS, data=pokeaman_train)\n",
    "model7_CS_fit = model7_CS_spec.fit()\n",
    "model7_CS_fit.summary().tables[-1] \n",
    "# \"Cond. No.\" is NOW 15.4 due to centering and scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b031dec",
   "metadata": {},
   "source": [
    "***ChatGPT Chat Summary***\n",
    "\n",
    "Here’s a summary of our conversation:\n",
    "\n",
    "1. **Explained Models**: We discussed several statistical models in the context of Pokémon data, such as **model3**, **model4**, **model5**, and others, including how changes like adding interaction terms, scaling, and centering continuous variables affect the models' performance.\n",
    "\n",
    "2. **Centering and Scaling**: You learned that **centering** data (subtracting the mean from each value) and **scaling** (dividing by the standard deviation) helps improve model accuracy and numerical stability. Centering shifts the data so it’s easier for the model to interpret, and scaling ensures that all variables are on the same scale, preventing one variable from dominating the model.\n",
    "\n",
    "3. **Multicollinearity**: We explored how multicollinearity (when predictors are highly correlated with each other) can affect model stability and generalization. By centering and scaling the data, multicollinearity is reduced, helping the model predict more reliably.\n",
    "\n",
    "4. **Interpretation of Statistical Terms**: We also discussed key terms like **R-squared**, **interaction terms**, and **condition number** in models, explaining their roles in assessing model accuracy, stability, and prediction performance.\n",
    "\n",
    "5. **The Role of Interaction Terms**: Interaction terms were introduced to better capture relationships between predictors (e.g., how **Attack** and **Speed** together influence **HP**) and improve model predictions.\n",
    "\n",
    "Let me know if you need further clarification on any points!\n",
    "\n",
    "link: https://chatgpt.com/share/67328c5d-6e88-800d-a4e1-34302f65803e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31c4db6",
   "metadata": {},
   "source": [
    "***Question 8***\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40f2a898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the linear formula for the model\n",
    "linear_form = 'HP ~ Attack + Defense'\n",
    "\n",
    "# Define the number of repetitions\n",
    "reps = 100\n",
    "\n",
    "# Arrays to store R-squared values\n",
    "in_sample_Rsquared = np.array([0.0]*reps)\n",
    "out_of_sample_Rsquared = np.array([0.0]*reps)\n",
    "\n",
    "# Run the loop to calculate R-squared values for each iteration\n",
    "for i in range(reps):\n",
    "    # Create random 50-50 train-test split\n",
    "    pokeaman_train, pokeaman_test = train_test_split(pokeaman, train_size=0.5)\n",
    "    \n",
    "    # Fit the model on the training set\n",
    "    final_model_fit = smf.ols(formula=linear_form, data=pokeaman_train).fit()\n",
    "    \n",
    "    # Calculate in-sample R-squared\n",
    "    in_sample_Rsquared[i] = final_model_fit.rsquared\n",
    "    \n",
    "    # Calculate out-of-sample R-squared on the test set\n",
    "    y_pred = final_model_fit.predict(pokeaman_test)\n",
    "    y_actual = pokeaman_test.HP\n",
    "    out_of_sample_Rsquared[i] = np.corrcoef(y_actual, y_pred)[0,1]**2\n",
    "\n",
    "# Create a DataFrame for results\n",
    "df = pd.DataFrame({\n",
    "    \"In Sample Performance (Rsquared)\": in_sample_Rsquared,\n",
    "    \"Out of Sample Performance (Rsquared)\": out_of_sample_Rsquared\n",
    "})\n",
    "\n",
    "# Plot results using Plotly\n",
    "fig = px.scatter(df, x=\"In Sample Performance (Rsquared)\", \n",
    "                 y=\"Out of Sample Performance (Rsquared)\",\n",
    "                 title=\"In-Sample vs Out-of-Sample R-squared Performance\")\n",
    "fig.update_layout(xaxis_title=\"In-Sample R-squared\",\n",
    "                  yaxis_title=\"Out-of-Sample R-squared\")\n",
    "fig.show(renderer = 'png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a807e95",
   "metadata": {},
   "source": [
    "The purpose of this code is to demostrate the relative relationship between the linear model's accuracy on predicting variation in sample vs out of sample. We observe that generally a high In-Sample R-squared value correlates with a low Out-of-Sample R-squared value. This is an indicator of overfitting within our model. \n",
    "\n",
    "***ChatGPT Chat Summary***\n",
    "\n",
    "Here’s a summary of the recent conversation:\n",
    "\n",
    "1. **Objective of Analysis**: We explored how to create multiple random train-test splits for a linear regression model on the Pokémon dataset and measure **in-sample** and **out-of-sample** R-squared performance in each iteration to evaluate the model's generalization.\n",
    "\n",
    "2. **Code Explanation**: The code uses a loop to:\n",
    "   - Randomly split the Pokémon data into training and testing sets in each iteration.\n",
    "   - Fit a linear regression model (`model3` specification) on the training data.\n",
    "   - Calculate **in-sample R-squared** (how well the model fits the training data) and **out-of-sample R-squared** (how well it predicts unseen data) for each iteration.\n",
    "   - Plot the results to compare **in-sample** and **out-of-sample** performance.\n",
    "\n",
    "3. **Interpreting Results**:\n",
    "   - If the **in-sample** and **out-of-sample R-squared** values are consistently close, it indicates that the model generalizes well.\n",
    "   - If there’s a big gap (especially if **in-sample R-squared** is much higher), it may suggest **overfitting** or sensitivity to specific train-test splits, indicating poor generalization.\n",
    "\n",
    "4. **Purpose of Demonstration**: By running multiple iterations, this method highlights the model’s robustness and whether it can generalize beyond the training data across different data splits. This insight helps identify overfitting or underfitting issues and assess model reliability.\n",
    "\n",
    "link: https://chatgpt.com/share/67328c5d-6e88-800d-a4e1-34302f65803e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d500569",
   "metadata": {},
   "source": [
    "***Question 9***\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abb71504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456 (original)\n",
      "'Out of sample' R-squared: 0.000671766381616773 (original)\n",
      "'In sample' R-squared:     0.5726118179916575 (gen1_predict_future)\n",
      "'Out of sample' R-squared: 0.11151363354803218 (gen1_predict_future)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model7_gen1_predict_future = smf.ols(formula=model7_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation==1])\n",
    "model7_gen1_predict_future_fit = model7_gen1_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model7_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation!=1].HP\n",
    "yhat = model7_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation!=1])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1_predict_future)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dd8dd1",
   "metadata": {},
   "source": [
    "Shows how well the gen1 linear regression model predicts the HP of future generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "134ee426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456 (original)\n",
      "'Out of sample' R-squared: 0.000671766381616773 (original)\n",
      "'In sample' R-squared:     0.3904756578094535 (gen1to5_predict_future)\n",
      "'Out of sample' R-squared: 0.23394915464343125 (gen1to5_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model7_gen1to5_predict_future = smf.ols(formula=model7_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation!=6])\n",
    "model7_gen1to5_predict_future_fit = model7_gen1to5_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model7_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation==6].HP\n",
    "yhat = model7_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation==6])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1to5_predict_future)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a670388d",
   "metadata": {},
   "source": [
    "Similair to the previous code, it takes a linear regression model generated from the HP data in gen1 - gen 5 and sees how well this data predicts the HP of future generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba1206bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908 (original)\n",
      "'Out of sample' R-squared: 0.001332647669736567 (original)\n",
      "'In sample' R-squared:     0.4433880517727282 (gen1_predict_future)\n",
      "'Out of sample' R-squared: 0.1932858534276128 (gen1_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model6_gen1_predict_future = smf.ols(formula=model6_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation==1])\n",
    "model6_gen1_predict_future_fit = model6_gen1_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model6_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation!=1].HP\n",
    "yhat = model6_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation!=1])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1_predict_future)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25409bf6",
   "metadata": {},
   "source": [
    "Uses the regression line generated from generation 1 pokeman to predict other generations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02db6658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908 (original)\n",
      "'Out of sample' R-squared: 0.001332647669736567 (original)\n",
      "'In sample' R-squared:     0.33517279824114776 (gen1to5_predict_future)\n",
      "'Out of sample' R-squared: 0.26262690178799936 (gen1to5_predict_future)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model6_gen1to5_predict_future = smf.ols(formula=model6_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation!=6])\n",
    "model6_gen1to5_predict_future_fit = model6_gen1to5_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model6_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation==6].HP\n",
    "yhat = model6_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation==6])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1to5_predict_future)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4588f466",
   "metadata": {},
   "source": [
    "Tests if the linear regression line generated from pokemon gen1-gen5 data can predict gen6 HP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a949684",
   "metadata": {},
   "source": [
    "We see that using previous generations' HP data is not an effective way to predict future pokemon's HP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7a6378",
   "metadata": {},
   "source": [
    "***ChatGPT Chat Summary***\n",
    "\n",
    "In this series of exchanges, you explored building and evaluating regression models to predict Pokémon HP based on various attributes, focusing on **in-sample** (training) and **out-of-sample** (testing) R-squared values as measures of model fit and generalization. You examined different model formulations by adding predictor variables, interactions, and transformations (like centering and scaling), and tested their generalization across generations, especially predicting unseen generations (like Generation 6).\n",
    "\n",
    "Key insights include:\n",
    "1. **Multicollinearity**: You analyzed how high condition numbers (from multicollinearity) indicate dependencies among predictors, which can reduce out-of-sample predictive accuracy.\n",
    "2. **Centering and Scaling**: You saw how centering and scaling reduce the condition number, improving stability.\n",
    "3. **Generalization Across Generations**: By training models on specific generations and testing on others, you aimed to understand whether Pokémon attributes generalize well across generations or need updates over time.\n",
    "\n",
    "Your goal is to build models that generalize well, effectively predicting Pokémon HP across generations without overfitting to specific training data nuances.\n",
    "\n",
    "link: https://chatgpt.com/share/67328c5d-6e88-800d-a4e1-34302f65803e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
